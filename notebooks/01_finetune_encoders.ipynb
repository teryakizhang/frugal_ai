{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjELygztS5RL"
      },
      "source": [
        "# Train and Finetune ML and BERT models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqxXMDrqS5RM"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yvqL0O9TUl-",
        "outputId": "244f8e8b-3d52-4aaf-eb18-b5d385a962ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.11/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from codecarbon) (8.2.0)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.21.1)\n",
            "Requirement already satisfied: psutil>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from codecarbon) (7.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.11.4)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from codecarbon) (12.0.0)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.1.0)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from codecarbon) (3.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from codecarbon) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from codecarbon) (0.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.9.0.post0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow->codecarbon) (2.9.0.20250516)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.11/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->codecarbon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->codecarbon) (0.4.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->codecarbon) (12.575.51)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from questionary->codecarbon) (3.0.51)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->codecarbon) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->codecarbon) (2.19.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.9)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.11/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets\n",
        "!pip install codecarbon\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoHz4-BxTQr7",
        "outputId": "72357755-0e50-4ee4-dc02-b169ae420128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAEMwINdS5RM"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForSequenceClassification,\n",
        "                          AutoModel,\n",
        "                          BertTokenizer,\n",
        "                          BertModel,\n",
        "                          DistilBertModel,\n",
        "                          RobertaModel,\n",
        "                          DebertaModel,\n",
        "                          DebertaV2Model)\n",
        "from huggingface_hub import (\n",
        "    PyTorchModelHubMixin,\n",
        "    notebook_login,\n",
        "    ModelCard,\n",
        "    ModelCardData,\n",
        "    EvalResult,\n",
        ")\n",
        "from datasets import DatasetDict, load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from codecarbon import (\n",
        "    EmissionsTracker,\n",
        "    track_emissions,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma3JVOyjS5RN"
      },
      "outputs": [],
      "source": [
        "notebook_login(new_session=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHWXzcyXS5RN"
      },
      "source": [
        "## Create custom dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gc2nTUNS5RN"
      },
      "outputs": [],
      "source": [
        "# Defining the TextDataset class\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        self.labels = torch.tensor([int(l[0]) for l in labels])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWWbxXI0IKn4"
      },
      "source": [
        "## Define text preprocessing helper function\n",
        "\n",
        "This function is used to preprocess text as part of the classical NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HnW5BCYUXop",
        "outputId": "a1367ee4-2003-4d31-f44c-839b4d57e656"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import contractions\n",
        "import re\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess(X):\n",
        "    lemmatizer  = WordNetLemmatizer()\n",
        "    preprocessed_texts = []\n",
        "    for doc in X:\n",
        "        # Expand contractions\n",
        "        expanded = contractions.fix(doc)\n",
        "        # Remove special characters\n",
        "        expanded = re.sub(r\"[^a-zA-Z0-9]\", \" \", expanded)\n",
        "        # Lowercase\n",
        "        lowered = expanded.lower()\n",
        "        # Tokenize and lemmatize\n",
        "        lemmatized = \" \".join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(lowered)])\n",
        "        preprocessed_texts.append(lemmatized)\n",
        "    return preprocessed_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4irfiWqS5RN"
      },
      "source": [
        "## Model set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqIX_hJHS5RN"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHrZXabGS5RO"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module, PyTorchModelHubMixin):\n",
        "    def __init__(self, num_labels=8,\n",
        "                 model_name=\"bert-base-uncased\",\n",
        "                 dropout_rate=0.05):\n",
        "        super().__init__()\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Load appropriate transformer backbone\n",
        "        if model_name.startswith(\"distilbert\"):\n",
        "            self.backbone = DistilBertModel.from_pretrained(model_name)\n",
        "        elif model_name.startswith(\"distilroberta\"):\n",
        "            self.backbone = DistilBertModel.from_pretrained(model_name)\n",
        "        elif model_name.startswith(\"roberta\"):\n",
        "            self.backbone = RobertaModel.from_pretrained(model_name)\n",
        "        elif \"deberta-v2\" in model_name or \"deberta-v3\" in model_name:\n",
        "            self.backbone = DebertaV2Model.from_pretrained(model_name)\n",
        "        elif model_name.startswith(\"bert\"):\n",
        "            self.backbone = BertModel.from_pretrained(model_name)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        self.config = self.backbone.config\n",
        "        self.config.num_labels = num_labels\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Get [CLS] representation\n",
        "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
        "            pooled_output = outputs.pooler_output\n",
        "        else:\n",
        "            pooled_output = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TransformerFreezeClassifier(nn.Module, PyTorchModelHubMixin):\n",
        "    \"\"\"\n",
        "    A transformer-based classifier with optional frozen layers.\n",
        "    Supports BERT, DistilBERT, RoBERTa, and DeBERTa(v1/v2).\n",
        "    \"\"\"\n",
        "    def __init__(self, num_labels=8,\n",
        "                 model_name=\"bert-base-uncased\",\n",
        "                 dropout_rate=0.05,\n",
        "                 freeze_layers=10):\n",
        "        super().__init__()\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Load the appropriate transformer backbone\n",
        "        if model_name.startswith(\"distilbert\"):\n",
        "            self.backbone = DistilBertModel.from_pretrained(model_name)\n",
        "        elif model_name.startswith(\"roberta\"):\n",
        "            self.backbone = RobertaModel.from_pretrained(model_name)\n",
        "        elif \"deberta-v2\" in model_name or \"deberta-v3\" in model_name:\n",
        "            self.backbone = DebertaV2Model.from_pretrained(model_name)\n",
        "        elif model_name.startswith(\"bert\"):\n",
        "            self.backbone = BertModel.from_pretrained(model_name)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        self.config = self.backbone.config\n",
        "        self.config.num_labels = num_labels\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
        "\n",
        "        # Freeze layers as requested\n",
        "        self.freeze_model_layers(freeze_layers)\n",
        "\n",
        "    def freeze_model_layers(self, freeze_layers):\n",
        "        \"\"\"\n",
        "        Freeze the embedding and first N encoder layers.\n",
        "        \"\"\"\n",
        "        backbone_type = type(self.backbone).__name__.lower()\n",
        "\n",
        "        if \"distilbert\" in backbone_type:\n",
        "            encoder_prefix = \"transformer.layer\"\n",
        "        elif \"bert\" in backbone_type or \"roberta\" in backbone_type:\n",
        "            encoder_prefix = \"encoder.layer\"\n",
        "        elif \"deberta\" in backbone_type:\n",
        "            encoder_prefix = \"encoder.layer\"\n",
        "        else:\n",
        "            raise ValueError(\"Unknown backbone type for freezing.\")\n",
        "\n",
        "        for name, param in self.backbone.named_parameters():\n",
        "            if name.startswith(\"embeddings\") or any(\n",
        "                name.startswith(f\"{encoder_prefix}.{i}\") for i in range(freeze_layers)\n",
        "            ):\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Handle pooled output across different model types\n",
        "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
        "            pooled_output = outputs.pooler_output\n",
        "        else:\n",
        "            pooled_output = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TfidfXGBClassifier():\n",
        "    def __init__(self, num_labels=8):\n",
        "        self.xgb_pipeline = Pipeline([\n",
        "            # TF-IDF vectorization\n",
        "            (\"tfidf\", TfidfVectorizer(max_features=2000, min_df=2, ngram_range=(1, 3))),\n",
        "            (\"classifier\", XGBClassifier(objective=\"multi:softmax\",\n",
        "                                        eval_metric='merror',\n",
        "                                        num_class=num_labels,\n",
        "                                        random_state=42))  # XGBoost\n",
        "        ])\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.xgb_pipeline.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.xgb_pipeline.predict(X)\n",
        "\n",
        "\n",
        "class ConspiracyClassifier768(\n",
        "    nn.Module,\n",
        "    PyTorchModelHubMixin\n",
        "):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super().__init__()\n",
        "        self.h1 = nn.Linear(768, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.h2 = nn.Linear(512, 512)\n",
        "        self.bn2 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.h3 = nn.Linear(512, 256)\n",
        "        self.bn3 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.h4 = nn.Linear(256, 128)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.h5 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        self.initialize_weights()\n",
        "\n",
        "\n",
        "    def forward(self, input_texts):\n",
        "        outputs = self.h1(input_texts)\n",
        "        outputs = self.bn1(outputs)\n",
        "        outputs = self.activation(outputs)\n",
        "        outputs = self.h2(outputs)\n",
        "        outputs = self.bn2(outputs)\n",
        "        outputs = self.activation(outputs)\n",
        "        outputs = self.h3(outputs)\n",
        "        outputs = self.bn3(outputs)\n",
        "        outputs = self.activation(outputs)\n",
        "        outputs = self.dropout(outputs)\n",
        "        outputs = self.h4(outputs)\n",
        "        outputs = self.bn4(outputs)\n",
        "        outputs = self.activation(outputs)\n",
        "        outputs = self.h5(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP-WWua-S5RO"
      },
      "source": [
        "### Train XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sevrlAIS5RO"
      },
      "outputs": [],
      "source": [
        "class TfidfXGBTrainer():\n",
        "    def __init__(self, model, dataset):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.train_texts, self.train_labels, self.val_texts, self.val_labels = self.prepare_dataset_tfidf()\n",
        "\n",
        "    def prepare_dataset_tfidf(self):\n",
        "        print(\"Loading dataset...\")\n",
        "        # Load the dataset\n",
        "        dataset = self.dataset\n",
        "\n",
        "        # Split dataset\n",
        "        train_texts = dataset[\"train\"][\"quote\"]\n",
        "        train_labels = [int(l[0]) for l in dataset[\"train\"][\"label\"]]\n",
        "        val_texts = dataset[\"test\"][\"quote\"]\n",
        "        val_labels = [int(l[0]) for l in dataset[\"test\"][\"label\"]]\n",
        "\n",
        "        train_texts_preprocessed = preprocess(train_texts)\n",
        "        val_texts_preprocessed = preprocess(val_texts)\n",
        "\n",
        "        print(\"Dataset loaded and dataloaders created.\")\n",
        "        return train_texts_preprocessed, train_labels, val_texts_preprocessed, val_labels\n",
        "\n",
        "    def train(self):\n",
        "        print(\"Training XGBoost model...\")\n",
        "        self.model.fit(self.train_texts, self.train_labels)\n",
        "        print(\"XGBoost model trained.\")\n",
        "\n",
        "\n",
        "    def evaluate(self):\n",
        "        print(\"Evaluating XGBoost model...\")\n",
        "        predictions = self.model.predict(self.val_texts)\n",
        "        accuracy = accuracy_score(self.val_labels, predictions)\n",
        "        f1 = f1_score(self.val_labels, predictions, average=\"weighted\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "        return accuracy, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85jEoZCmS5RO"
      },
      "outputs": [],
      "source": [
        "class BertTrainer():\n",
        "    def __init__(self, model, tokenizer, dataset, batch_size=32, epochs=3, test=False):\n",
        "        self.model = model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
        "        self.embedding_model = AutoModel.from_pretrained(tokenizer)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.training_progress = []\n",
        "        self.test = test\n",
        "\n",
        "        self.train_dataloader, self.val_dataloader = self.prepare_dataset_bert()\n",
        "\n",
        "        if torch.backends.mps.is_available():\n",
        "            self.device = torch.device(\"mps\")\n",
        "            torch.mps.empty_cache()\n",
        "        elif torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        self.embedding_model.to(self.device)\n",
        "\n",
        "\n",
        "    def prepare_dataset_bert(self):\n",
        "        print(\"Loading dataset...\")\n",
        "        # Load the dataset\n",
        "        dataset = self.dataset\n",
        "\n",
        "        # Split dataset\n",
        "        train_texts = dataset[\"train\"][\"quote\"]\n",
        "        train_labels = dataset[\"train\"][\"label\"]\n",
        "        val_texts = dataset[\"test\"][\"quote\"]\n",
        "        val_labels = dataset[\"test\"][\"label\"]\n",
        "\n",
        "\n",
        "        # Create the datasets\n",
        "        train_dataset = TextDataset(train_texts, train_labels, self.tokenizer)\n",
        "        val_dataset = TextDataset(val_texts, val_labels, self.tokenizer)\n",
        "\n",
        "        # Create the dataloaders\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        print(\"Dataset loaded and dataloaders created.\")\n",
        "        return train_dataloader, val_dataloader\n",
        "\n",
        "\n",
        "    def custom_print_time(self, additional_text):\n",
        "        \"\"\"\n",
        "        Custom function to print the current time with a message.\n",
        "        \"\"\"\n",
        "        time_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        print(f\"{time_str} {additional_text}\")\n",
        "\n",
        "\n",
        "    def model_metrics(self, model, dataloader):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            total_loss = 0\n",
        "            total_correct = 0\n",
        "            total_length = 0\n",
        "            for batch in dataloader:\n",
        "                input_ids = batch[\"input_ids\"].to(self.device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
        "                labels = batch[\"labels\"].to(self.device)\n",
        "\n",
        "                if isinstance(self.model, ConspiracyClassifier768):\n",
        "                    embeddings = self.get_embeddings(input_ids, attention_mask, self.embedding_model)\n",
        "                    outputs = self.model(embeddings)\n",
        "                else:\n",
        "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                predicted = torch.argmax(outputs, 1).cpu().numpy()\n",
        "                labels = labels.cpu().numpy()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                total_correct += (predicted == labels).sum().item()\n",
        "                total_length += len(labels)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            average_loss = total_loss / len(dataloader)\n",
        "            average_acc = total_correct / total_length\n",
        "\n",
        "        model.train()\n",
        "        return average_loss, average_acc\n",
        "\n",
        "    def eval_model_status(self, epoch):\n",
        "        train_loss, train_acc = self.model_metrics(self.model, self.train_dataloader)\n",
        "        test_loss, test_acc = self.model_metrics(self.model, self.val_dataloader)\n",
        "        loss_str = f\"Loss: Train {train_loss:0.3f}, Test {test_loss:0.3f}\"\n",
        "        acc_str = f\"Acc: Train {train_acc:0.3f}, Test {test_acc:0.3f}\"\n",
        "        self.custom_print_time(f\"Epoch {epoch+1:2}/{self.epochs} done. {loss_str}; and {acc_str}\")\n",
        "        metrics = dict(\n",
        "            epoch=epoch,\n",
        "            train_loss=train_loss,\n",
        "            train_acc=train_acc,\n",
        "            test_loss=test_loss,\n",
        "            test_acc=test_acc,\n",
        "        )\n",
        "        return metrics\n",
        "\n",
        "    def get_embeddings(self, input_ids, attention_mask, embedding_model):\n",
        "        with torch.no_grad():\n",
        "            embeddings = embedding_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
        "        return embeddings\n",
        "\n",
        "    def train_model(self, lr=2e-5):\n",
        "        # Define the optimizer\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        print(\"Training the model...\")\n",
        "        # Training loop\n",
        "        if not self.test:\n",
        "            for epoch in range(self.epochs):\n",
        "                total_loss = 0\n",
        "                self.custom_print_time(f\"Epoch {epoch + 1}/{self.epochs}\")\n",
        "                for batch in self.train_dataloader:\n",
        "                    input_ids = batch[\"input_ids\"].to(self.device)\n",
        "                    attention_mask = batch[\"attention_mask\"].to(self.device)\n",
        "                    labels = batch[\"labels\"].to(self.device)\n",
        "\n",
        "                    if isinstance(self.model, ConspiracyClassifier768):\n",
        "                        embeddings = self.get_embeddings(input_ids, attention_mask, self.embedding_model)\n",
        "                        outputs = self.model(embeddings)\n",
        "                    else:\n",
        "                        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                eval_metrics = self.eval_model_status(epoch)\n",
        "                self.training_progress.append(eval_metrics)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        else:\n",
        "            print(\"Test mode enabled, skipping training.\")\n",
        "            eval_metrics = self.eval_model_status(0)\n",
        "            self.training_progress.append(eval_metrics)\n",
        "\n",
        "        print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ7Tjh4VsHRj"
      },
      "source": [
        "## Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFbjNSpRS5RP",
        "outputId": "4b2fdb87-e829-4ee5-a60a-01805014a067"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Configuration of models to be experimented with\n",
        "\n",
        "model_configs = {\n",
        "    # \"tfidf-xgboost\": {\n",
        "    #     \"name\": \"TFIDF + XGBoost\",\n",
        "    #     \"tokenizer\": \"tfidf\",\n",
        "    #     \"model\": TfidfXGBClassifier()\n",
        "    # },\n",
        "    # \"bert-base-uncased\": {\n",
        "    #     \"name\": \"BERT Base Uncased\",\n",
        "    #     \"tokenizer\": \"bert-base-uncased\",\n",
        "    #     \"model\": TransformerClassifier(model_name=\"bert-base-uncased\"),\n",
        "    # },\n",
        "    # \"bert-base-uncased-freeze-10\": {\n",
        "    #     \"name\": \"BERT Base Uncased with 10 Frozen Layers\",\n",
        "    #     \"tokenizer\": \"bert-base-uncased\",\n",
        "    #     \"model\": TransformerFreezeClassifier(model_name=\"bert-base-uncased\", freeze_layers=10),\n",
        "    # },\n",
        "    #     \"bert-base-uncased-freeze-8\": {\n",
        "    #     \"name\": \"BERT Base Uncased with 8 Frozen Layers\",\n",
        "    #     \"tokenizer\": \"bert-base-uncased\",\n",
        "    #     \"model\": TransformerFreezeClassifier(model_name=\"bert-base-uncased\", freeze_layers=8),\n",
        "    # },\n",
        "    # \"distilbert-base-uncased\": {\n",
        "    #     \"name\": \"DistilBERT\",\n",
        "    #     \"tokenizer\": \"distilbert-base-uncased\",\n",
        "    #     \"model\": TransformerClassifier(model_name=\"distilbert-base-uncased\"),\n",
        "    # },\n",
        "    # \"roberta-base\": {\n",
        "    #     \"name\": \"RoBERTa Base\",\n",
        "    #     \"tokenizer\": \"roberta-base\",\n",
        "    #     \"model\": TransformerClassifier(model_name=\"roberta-base\"),\n",
        "    # },\n",
        "    # \"roberta-base-freeze\": {\n",
        "    #     \"name\": \"RoBERTa Base with 8 frozen layers\",\n",
        "    #     \"tokenizer\": \"roberta-base\",\n",
        "    #     \"model\": TransformerFreezeClassifier(model_name=\"roberta-base\", freeze_layers=8),\n",
        "    # },\n",
        "    \"roberta-base-freeze\": {\n",
        "        \"name\": \"RoBERTa Base with 10 frozen layers\",\n",
        "        \"tokenizer\": \"roberta-base\",\n",
        "        \"model\": TransformerFreezeClassifier(model_name=\"roberta-base\", freeze_layers=10),\n",
        "    },\n",
        "    # \"distilroberta-base\": {\n",
        "    #     \"name\": \"DistilRoBERTa Base\",\n",
        "    #     \"tokenizer\": \"distilroberta-base\",\n",
        "    #     \"model\": TransformerClassifier(model_name=\"distilroberta-base\"),\n",
        "    # },\n",
        "    # 'deberta-v3-base': {\n",
        "    #     \"name\": \"DeBERTa v3 base\",\n",
        "    #     \"tokenizer\": \"microsoft/deberta-v3-base\",\n",
        "    #     \"model\": TransformerClassifier(model_name=\"microsoft/deberta-v3-base\"),\n",
        "    # },\n",
        "    # 'deberta-v3-base-freeze': {\n",
        "    #     \"name\": \"DeBERTa v3 base with 8 frozen layers\",\n",
        "    #     \"tokenizer\": \"microsoft/deberta-v3-base\",\n",
        "    #     \"model\": TransformerFreezeClassifier(model_name=\"microsoft/deberta-v3-base\", freeze_layers=8),\n",
        "    # },\n",
        "    'deberta-v3-base-freeze': {\n",
        "        \"name\": \"DeBERTa v3 base with 10 frozen layers\",\n",
        "        \"tokenizer\": \"microsoft/deberta-v3-base\",\n",
        "        \"model\": TransformerFreezeClassifier(model_name=\"microsoft/deberta-v3-base\", freeze_layers=10),\n",
        "    },\n",
        "    # \"conspiracy-768\": {\n",
        "    #     \"name\": \"custom MLP 768 model\",\n",
        "    #     \"tokenizer\": \"sentence-transformers/all-distilroberta-v1\",\n",
        "    #     \"model\": ConspiracyClassifier768(),\n",
        "    # },\n",
        "}\n",
        "\n",
        "models = model_configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4kj16PjS5RP"
      },
      "source": [
        "# Measure carbon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrhY9aAyxLPY"
      },
      "source": [
        "## Measure training carbon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeDvhgUAS5RP"
      },
      "outputs": [],
      "source": [
        "from codecarbon import EmissionsTracker\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwwPx-EyS5RP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_model_performance(model, device, dataloader):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a trained model on a given dataloader.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        dataloader: DataLoader containing the evaluation dataset.\n",
        "\n",
        "    Returns:\n",
        "        int: Accuracy of the model on the evaluation dataset.\n",
        "        int: F1 score of the model on the evaluation dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    f1 = f1_score(all_labels, all_predictions, average=\"weighted\")\n",
        "\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhbPjLZFTWl7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_model_performance_embed(model, embedding_model, device, dataloader):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a trained model that requires a separate embedding model.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        dataloader: DataLoader containing the evaluation dataset.\n",
        "\n",
        "    Returns:\n",
        "        int: Accuracy of the model on the evaluation dataset.\n",
        "        int: F1 score of the model on the evaluation dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            embeddings = embedding_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output.to(device)\n",
        "            outputs = model(embeddings)\n",
        "\n",
        "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    f1 = f1_score(all_labels, all_predictions, average=\"weighted\")\n",
        "\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSBRRq91S5RP"
      },
      "outputs": [],
      "source": [
        "# Run models and measure carbon footprint\n",
        "def train_eval_model_with_tracking(model_config, dataset, batch_size=32, epochs=3, test_mode=False, lr=2e-5):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model while tracking its carbon footprint.\n",
        "\n",
        "    Args:\n",
        "        model: The model to be trained.\n",
        "        tokenizer: The tokenizer to be used with the model.\n",
        "        dataset: The dataset to be used for training and evaluation.\n",
        "        batch_size: The batch size for training.\n",
        "        epochs: The number of epochs for training.\n",
        "        test_mode: If True, the model will not be trained, only evaluated.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the model, energy consumed, carbon emissions, hardware used, training time, accuracy, and F1 score.\n",
        "    \"\"\"\n",
        "\n",
        "    # Train NN models\n",
        "\n",
        "    if 'tfidf' in model_config['name'].lower():\n",
        "        training_run = TfidfXGBTrainer(\n",
        "            model=model_config[\"model\"],\n",
        "            dataset=dataset,\n",
        "        )\n",
        "        start_time = time.time()\n",
        "        tracker = EmissionsTracker(project_name=\"FrugalAI_model_carbon\",\n",
        "                                measure_power_secs=10)\n",
        "        tracker.start()\n",
        "\n",
        "        training_run.train()\n",
        "\n",
        "\n",
        "        end_time = time.time()\n",
        "        emissions = tracker.stop()\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy, f1 = training_run.evaluate()\n",
        "\n",
        "        batch_size = 'N/A'\n",
        "        epochs = 'N/A'\n",
        "\n",
        "    else:\n",
        "        training_run = BertTrainer(\n",
        "            model=model_config[\"model\"],\n",
        "            tokenizer=model_config[\"tokenizer\"],\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            test=test_mode\n",
        "        )\n",
        "\n",
        "        start_time = time.time()\n",
        "        tracker = EmissionsTracker(project_name=\"FrugalAI_model_carbon\",\n",
        "                                measure_power_secs=10)\n",
        "        tracker.start()\n",
        "\n",
        "        training_run.train_model(lr=lr)\n",
        "\n",
        "        end_time = time.time()\n",
        "        emissions = tracker.stop()\n",
        "\n",
        "\n",
        "        if isinstance(training_run.model, ConspiracyClassifier768):\n",
        "            accuracy, f1 = evaluate_model_performance_embed(\n",
        "                training_run.model, training_run.embedding_model, training_run.device, training_run.val_dataloader\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            accuracy, f1 = evaluate_model_performance(\n",
        "                    training_run.model, training_run.device, training_run.val_dataloader\n",
        "                )\n",
        "\n",
        "    results = {\n",
        "        \"model_name\": model_config['name'],\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        'location': tracker._geo.country_iso_code,\n",
        "        \"energy_consumed_kwh\": tracker._total_energy.kWh,\n",
        "        \"carbon_emissions_kgco2\": emissions,\n",
        "        'cpu_energy_kwh': tracker._total_cpu_energy.kWh,\n",
        "        'gpu_energy_kwh': tracker._total_gpu_energy.kWh,\n",
        "        'ram_energy_kwh': tracker._total_ram_energy.kWh,\n",
        "        'hardware': tracker._hardware,\n",
        "        \"training_time\": end_time - start_time,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "    }\n",
        "\n",
        "\n",
        "    return training_run.model, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lwL_nDAS5RP"
      },
      "outputs": [],
      "source": [
        "# trained_models = {}\n",
        "# results_list = []\n",
        "\n",
        "# dataset = load_dataset(\"quotaclimat/frugalaichallenge-text-train\")\n",
        "\n",
        "# for model_name, model_config in models.items():\n",
        "#     print(f\"Training {model_name}\")\n",
        "\n",
        "#     model, results = train_eval_model_with_tracking(\n",
        "#         model_config=model_config,\n",
        "#         dataset=dataset,\n",
        "#         batch_size=32,\n",
        "#         epochs=3,\n",
        "#     )\n",
        "\n",
        "#     trained_models[model_name] = model\n",
        "#     results_list.append(results)\n",
        "#     print(f\"Results for {model_name}: {results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f37b38df4fc548f397169c23eef16e9a",
            "dd74ff432f444554a1646f427bd6a334",
            "9aa85b52e8dd49769f3817d5a8b4451e",
            "697a46fec4024ddfba776ea4ba884e96",
            "e727db4208914d249fda094b78d69979",
            "20ba3181722045c3a2e02d1e5e78fbbe",
            "5e1e9b7008f449da86b25e6eb0985d1d",
            "fed7187a02c640ab93102aa2833ca60d",
            "bf69da8220e34346ad8dc7243fbffe86",
            "0e238f16ea15494b827d374fa1895414",
            "5ac94ead99494814abb25e8902fce452",
            "5a944fd6229049508970b6809e378cf4",
            "f974fd9b5afb4555986d967b6a617bd1",
            "647661c1a199416684bf7142718131ee",
            "58f41fb38cac4991be53a686779003cf",
            "98730ba2164d424a9bf52d4ea537a2fb",
            "273f384349204619a984c3faef9ca7f5",
            "d676c93e4e654b00a70b81a912a48c01",
            "95e8b5e274c94fb6a2817304f806445c",
            "9a05e021b9e74845ad432e5213ddf1e2",
            "78212f68102642c4ac71a39a6939e682",
            "b136d121c449459fa93793c20bd2ba46",
            "15e5119de9a64878b3041b568c8bb5e5",
            "86c6200dbf78495985faac7ebc3c13c8",
            "84d6ab2621564ac29c2dd6413522b57e",
            "fa804938437345ada6e20a165fb45c48",
            "bf9214cc4c7646309a6d83d70ed05035",
            "08cc1532e09c4c8ab3d91567ccbfef51",
            "3570af93f3754f6eb8cd5a5495be3c4f",
            "72c3750099ed4d9b8790242bd2f427c7",
            "b9c4e009ad96488798f584be79580d48",
            "4df74c468c72436280f9235de4af7750",
            "1482db60b0b148219a1af377e314a836",
            "ad30762e20e54ebd9416252c948a50e0",
            "bc912834d1164d46b14877b6f6d5744f",
            "1aa87ed8695342cda6a3f67798409632",
            "13046dc8761541e3bebf328c72afd398",
            "f70f8d63577a409c9975ec3083b6fd22",
            "d8895c24f4f2461bafcdc0373faaba77",
            "9f57badf4825450e853ded9d536d1084",
            "68c7df445a7b4e9aac4c729407beb599",
            "ff783e0ce2ab489d96eecd75962e87bb",
            "a20b62c740c845cfa764369b2c2b2dbf",
            "812c40705d894f4197eed3d54cb68aed",
            "a8572f0a9e6b42eb9d92d9948a7632d7",
            "6c46f87504da4f3fa258c067f46f87c8",
            "b2f4a4ed440a4d6bb0c056d96aae5b84",
            "63ae69ae808f4ad99ae9a801a010c179",
            "08e88617d3374dd286d805e4f24aa260",
            "53c6d028c83940dfa3428e6fdc3071b6",
            "74eabd5c535d48d6a2613527faa5e274",
            "880546ae3973404ea7929cb98fc7be35",
            "ced467c702cb4a36a26461445ccc9630",
            "c0ccd26bbd9642dcaa1be341a59faa9e",
            "3c827ebdad5049a8b1d1571c39f08deb",
            "a86b0ae2a5c94e75ab1221d8ec10fb64",
            "62584308dd864b318fb915bf1d24e67a",
            "a24345de7b4d4ca28110175604443a38",
            "288539f842d54ed5ac9f3c73fe4f7e74",
            "e483367bf2ba4af99828a69a3262783c",
            "9c18183b7ce9490fb7621f82a775e6f4",
            "70dd9a5bf1f547169630d5356a23861c",
            "72fc86bfcaf74466851bcd1ed04c97ee",
            "cc43778e79344708a27d09ce5522b3eb",
            "71d68f51d53f4ce58e2ffbaf73689c94",
            "18bf2c73af9a4db08663cb6b892d696a",
            "cad189f48f5444a9abfe750dade2e000",
            "5030bba89344414c8415107d84db6c64",
            "2e150f1b4500422eae399f07ab617043",
            "d75ec8c5d74a44f7a8e4b2f69c00254c",
            "16010d7c4b6b4d5f8cd20094f229d144",
            "080168109e674466b8fda1a427a97c68",
            "c43938df871543d2bf97573ca66823b2",
            "d9fabe1d1cc54b06aa66e47d17c6d3aa",
            "34d85da4460740ba8192d3ca5cf003d5",
            "b832ef14dd1e4c51845c5b86dcaf6bb1",
            "a04fe8ed667846e78c6dc435d7b717f4"
          ]
        },
        "id": "3n90ohw1raDw",
        "outputId": "3b1bb038-7937-4ac5-b739-8d2a58584770"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f37b38df4fc548f397169c23eef16e9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training roberta-base-freeze\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a944fd6229049508970b6809e378cf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15e5119de9a64878b3041b568c8bb5e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad30762e20e54ebd9416252c948a50e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8572f0a9e6b42eb9d92d9948a7632d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded and dataloaders created.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 13:12:08] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 13:12:08] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 13:12:08] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 13:12:09] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 13:12:09] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 13:12:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 13:12:09] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 13:12:09] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 13:12:09] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 13:12:09] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 13:12:09] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 13:12:09]   Platform system: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 13:12:09]   Python version: 3.11.12\n",
            "[codecarbon INFO @ 13:12:09]   CodeCarbon version: 3.0.1\n",
            "[codecarbon INFO @ 13:12:09]   Available RAM : 52.960 GB\n",
            "[codecarbon INFO @ 13:12:09]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 13:12:09]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 13:12:09]   GPU count: 1\n",
            "[codecarbon INFO @ 13:12:09]   GPU model: 1 x NVIDIA L4\n",
            "[codecarbon INFO @ 13:12:09] Emissions data (if any) will be saved to file /content/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "2025-05-16 13:12:09 Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:12:19] Energy consumed for RAM : 0.000056 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:12:19] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:12:19] Energy consumed for All CPU : 0.000118 kWh\n",
            "[codecarbon INFO @ 13:12:19] Energy consumed for all GPUs : 0.000188 kWh. Total GPU Power : 67.75860648294241 W\n",
            "[codecarbon INFO @ 13:12:19] 0.000362 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:12:29] Energy consumed for RAM : 0.000111 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:12:29] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:12:29] Energy consumed for All CPU : 0.000236 kWh\n",
            "[codecarbon INFO @ 13:12:29] Energy consumed for all GPUs : 0.000388 kWh. Total GPU Power : 71.95427449268223 W\n",
            "[codecarbon INFO @ 13:12:29] 0.000735 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:12:39] Energy consumed for RAM : 0.000167 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:12:39] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:12:39] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 13:12:39] Energy consumed for all GPUs : 0.000588 kWh. Total GPU Power : 71.9365170626323 W\n",
            "[codecarbon INFO @ 13:12:39] 0.001109 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:12:49] Energy consumed for RAM : 0.000222 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:12:49] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:12:49] Energy consumed for All CPU : 0.000472 kWh\n",
            "[codecarbon INFO @ 13:12:49] Energy consumed for all GPUs : 0.000790 kWh. Total GPU Power : 72.6667956196049 W\n",
            "[codecarbon INFO @ 13:12:49] 0.001484 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:12:59] Energy consumed for RAM : 0.000278 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:12:59] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:12:59] Energy consumed for All CPU : 0.000590 kWh\n",
            "[codecarbon INFO @ 13:12:59] Energy consumed for all GPUs : 0.000989 kWh. Total GPU Power : 71.94661687505767 W\n",
            "[codecarbon INFO @ 13:12:59] 0.001857 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:13:09] Energy consumed for RAM : 0.000333 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:13:09] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:13:09] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 13:13:09] Energy consumed for all GPUs : 0.001189 kWh. Total GPU Power : 71.96146016816768 W\n",
            "[codecarbon INFO @ 13:13:09] 0.002231 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:13:14 Epoch  1/5 done. Loss: Train 1.967, Test 1.997; and Acc: Train 0.269, Test 0.252\n",
            "2025-05-16 13:13:14 Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:13:19] Energy consumed for RAM : 0.000389 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:13:19] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:13:19] Energy consumed for All CPU : 0.000826 kWh\n",
            "[codecarbon INFO @ 13:13:19] Energy consumed for all GPUs : 0.001389 kWh. Total GPU Power : 71.9391045042819 W\n",
            "[codecarbon INFO @ 13:13:19] 0.002604 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:13:29] Energy consumed for RAM : 0.000444 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:13:29] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:13:29] Energy consumed for All CPU : 0.000944 kWh\n",
            "[codecarbon INFO @ 13:13:29] Energy consumed for all GPUs : 0.001589 kWh. Total GPU Power : 71.94025017409693 W\n",
            "[codecarbon INFO @ 13:13:29] 0.002977 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:13:29] 0.017518 g.CO2eq/s mean an estimation of 552.4605237647681 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:13:39] Energy consumed for RAM : 0.000500 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:13:39] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:13:39] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 13:13:39] Energy consumed for all GPUs : 0.001789 kWh. Total GPU Power : 71.97295071005694 W\n",
            "[codecarbon INFO @ 13:13:39] 0.003351 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:13:49] Energy consumed for RAM : 0.000555 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:13:49] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:13:49] Energy consumed for All CPU : 0.001180 kWh\n",
            "[codecarbon INFO @ 13:13:49] Energy consumed for all GPUs : 0.001989 kWh. Total GPU Power : 71.94243205832274 W\n",
            "[codecarbon INFO @ 13:13:49] 0.003724 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:13:59] Energy consumed for RAM : 0.000611 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:13:59] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:13:59] Energy consumed for All CPU : 0.001298 kWh\n",
            "[codecarbon INFO @ 13:13:59] Energy consumed for all GPUs : 0.002188 kWh. Total GPU Power : 71.98498633804343 W\n",
            "[codecarbon INFO @ 13:13:59] 0.004097 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:14:09] Energy consumed for RAM : 0.000666 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:14:09] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:14:09] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 13:14:09] Energy consumed for all GPUs : 0.002388 kWh. Total GPU Power : 71.94776454617399 W\n",
            "[codecarbon INFO @ 13:14:09] 0.004471 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:14:19] Energy consumed for RAM : 0.000722 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:14:19] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:14:19] Energy consumed for All CPU : 0.001534 kWh\n",
            "[codecarbon INFO @ 13:14:19] Energy consumed for all GPUs : 0.002588 kWh. Total GPU Power : 71.9792408937384 W\n",
            "[codecarbon INFO @ 13:14:19] 0.004844 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:14:21 Epoch  2/5 done. Loss: Train 1.943, Test 1.982; and Acc: Train 0.269, Test 0.252\n",
            "2025-05-16 13:14:21 Epoch 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:14:29] Energy consumed for RAM : 0.000777 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:14:29] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:14:29] Energy consumed for All CPU : 0.001652 kWh\n",
            "[codecarbon INFO @ 13:14:29] Energy consumed for all GPUs : 0.002788 kWh. Total GPU Power : 71.97397949009832 W\n",
            "[codecarbon INFO @ 13:14:29] 0.005218 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:14:39] Energy consumed for RAM : 0.000833 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:14:39] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:14:39] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 13:14:39] Energy consumed for all GPUs : 0.002988 kWh. Total GPU Power : 71.96602851019304 W\n",
            "[codecarbon INFO @ 13:14:39] 0.005591 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:14:49] Energy consumed for RAM : 0.000888 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:14:49] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:14:49] Energy consumed for All CPU : 0.001888 kWh\n",
            "[codecarbon INFO @ 13:14:49] Energy consumed for all GPUs : 0.003188 kWh. Total GPU Power : 71.96378196751019 W\n",
            "[codecarbon INFO @ 13:14:49] 0.005964 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:14:49] 0.017577 g.CO2eq/s mean an estimation of 554.3067219913296 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:14:59] Energy consumed for RAM : 0.000944 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:14:59] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:14:59] Energy consumed for All CPU : 0.002006 kWh\n",
            "[codecarbon INFO @ 13:14:59] Energy consumed for all GPUs : 0.003387 kWh. Total GPU Power : 71.95104761168047 W\n",
            "[codecarbon INFO @ 13:14:59] 0.006338 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:15:09] Energy consumed for RAM : 0.001000 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:15:09] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:15:09] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 13:15:09] Energy consumed for all GPUs : 0.003587 kWh. Total GPU Power : 71.9402097125134 W\n",
            "[codecarbon INFO @ 13:15:09] 0.006711 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:15:19] Energy consumed for RAM : 0.001055 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:15:19] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:15:19] Energy consumed for All CPU : 0.002242 kWh\n",
            "[codecarbon INFO @ 13:15:19] Energy consumed for all GPUs : 0.003787 kWh. Total GPU Power : 71.92956453123995 W\n",
            "[codecarbon INFO @ 13:15:19] 0.007084 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:15:28 Epoch  3/5 done. Loss: Train 1.929, Test 1.970; and Acc: Train 0.269, Test 0.252\n",
            "2025-05-16 13:15:28 Epoch 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:15:29] Energy consumed for RAM : 0.001111 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:15:29] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:15:29] Energy consumed for All CPU : 0.002360 kWh\n",
            "[codecarbon INFO @ 13:15:29] Energy consumed for all GPUs : 0.003987 kWh. Total GPU Power : 71.93062708313823 W\n",
            "[codecarbon INFO @ 13:15:29] 0.007457 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:15:39] Energy consumed for RAM : 0.001166 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:15:39] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:15:39] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 13:15:39] Energy consumed for all GPUs : 0.004186 kWh. Total GPU Power : 71.96207848515341 W\n",
            "[codecarbon INFO @ 13:15:39] 0.007831 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:15:49] Energy consumed for RAM : 0.001222 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:15:49] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:15:49] Energy consumed for All CPU : 0.002596 kWh\n",
            "[codecarbon INFO @ 13:15:49] Energy consumed for all GPUs : 0.004386 kWh. Total GPU Power : 71.95452484421703 W\n",
            "[codecarbon INFO @ 13:15:49] 0.008204 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:15:59] Energy consumed for RAM : 0.001277 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:15:59] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:15:59] Energy consumed for All CPU : 0.002714 kWh\n",
            "[codecarbon INFO @ 13:15:59] Energy consumed for all GPUs : 0.004586 kWh. Total GPU Power : 71.9702176120566 W\n",
            "[codecarbon INFO @ 13:15:59] 0.008578 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:16:09] Energy consumed for RAM : 0.001333 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:16:09] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:09] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 13:16:09] Energy consumed for all GPUs : 0.004786 kWh. Total GPU Power : 71.94584278054998 W\n",
            "[codecarbon INFO @ 13:16:09] 0.008951 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:16:09] 0.017575 g.CO2eq/s mean an estimation of 554.2570975941071 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:16:19] Energy consumed for RAM : 0.001388 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:16:19] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:19] Energy consumed for All CPU : 0.002950 kWh\n",
            "[codecarbon INFO @ 13:16:19] Energy consumed for all GPUs : 0.004986 kWh. Total GPU Power : 71.93364450566085 W\n",
            "[codecarbon INFO @ 13:16:19] 0.009324 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:16:29] Energy consumed for RAM : 0.001444 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:16:29] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:29] Energy consumed for All CPU : 0.003068 kWh\n",
            "[codecarbon INFO @ 13:16:29] Energy consumed for all GPUs : 0.005185 kWh. Total GPU Power : 71.92853569030149 W\n",
            "[codecarbon INFO @ 13:16:29] 0.009697 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:16:35 Epoch  4/5 done. Loss: Train 1.916, Test 1.959; and Acc: Train 0.269, Test 0.252\n",
            "2025-05-16 13:16:35 Epoch 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:16:39] Energy consumed for RAM : 0.001499 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:16:39] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:39] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 13:16:39] Energy consumed for all GPUs : 0.005385 kWh. Total GPU Power : 71.95186664829232 W\n",
            "[codecarbon INFO @ 13:16:39] 0.010071 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:16:49] Energy consumed for RAM : 0.001555 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:16:49] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:49] Energy consumed for All CPU : 0.003304 kWh\n",
            "[codecarbon INFO @ 13:16:49] Energy consumed for all GPUs : 0.005585 kWh. Total GPU Power : 71.98227861519253 W\n",
            "[codecarbon INFO @ 13:16:49] 0.010444 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:16:59] Energy consumed for RAM : 0.001610 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:16:59] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:59] Energy consumed for All CPU : 0.003422 kWh\n",
            "[codecarbon INFO @ 13:16:59] Energy consumed for all GPUs : 0.005785 kWh. Total GPU Power : 71.96816275863729 W\n",
            "[codecarbon INFO @ 13:16:59] 0.010817 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:17:09] Energy consumed for RAM : 0.001666 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:17:09] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:09] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 13:17:09] Energy consumed for all GPUs : 0.005985 kWh. Total GPU Power : 71.9600715694724 W\n",
            "[codecarbon INFO @ 13:17:09] 0.011191 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:17:19] Energy consumed for RAM : 0.001721 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:17:19] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:19] Energy consumed for All CPU : 0.003658 kWh\n",
            "[codecarbon INFO @ 13:17:19] Energy consumed for all GPUs : 0.006185 kWh. Total GPU Power : 71.93768653565988 W\n",
            "[codecarbon INFO @ 13:17:19] 0.011564 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:17:29] Energy consumed for RAM : 0.001777 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:17:29] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:29] Energy consumed for All CPU : 0.003776 kWh\n",
            "[codecarbon INFO @ 13:17:29] Energy consumed for all GPUs : 0.006386 kWh. Total GPU Power : 72.67239743867168 W\n",
            "[codecarbon INFO @ 13:17:29] 0.011940 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:17:29] 0.017587 g.CO2eq/s mean an estimation of 554.6316872870693 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:17:39] Energy consumed for RAM : 0.001832 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:17:39] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:39] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 13:17:39] Energy consumed for all GPUs : 0.006586 kWh. Total GPU Power : 71.9359353657037 W\n",
            "[codecarbon INFO @ 13:17:39] 0.012313 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:17:43] Energy consumed for RAM : 0.001852 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:17:43] Delta energy consumed for CPU with constant : 0.000042 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:43] Energy consumed for All CPU : 0.003936 kWh\n",
            "[codecarbon INFO @ 13:17:43] Energy consumed for all GPUs : 0.006656 kWh. Total GPU Power : 71.54519853530155 W\n",
            "[codecarbon INFO @ 13:17:43] 0.012444 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:17:43 Epoch  5/5 done. Loss: Train 1.903, Test 1.947; and Acc: Train 0.269, Test 0.252\n",
            "Training complete.\n",
            "Results for roberta-base-freeze: {'model_name': 'RoBERTa Base with 8 frozen layers', 'batch_size': 32, 'epochs': 5, 'location': 'SGP', 'energy_consumed_kwh': 0.012443777693952045, 'carbon_emissions_kgco2': 0.005858318994091826, 'cpu_energy_kwh': 0.003935813959234715, 'gpu_energy_kwh': 0.006656020047034, 'ram_energy_kwh': 0.0018519436876833302, 'hardware': [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 85W [generic]), GPU() (NVIDIA L4)], 'training_time': 335.02156925201416, 'accuracy': 0.25184577522559476, 'f1_score': 0.10133244167006238}\n",
            "Results for roberta-base-freeze appended to /content/drive/MyDrive/Colab Notebooks/FrugalAI/results/train_results_20250516131155/running_results.csv\n",
            "Training deberta-v3-base-freeze\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a86b0ae2a5c94e75ab1221d8ec10fb64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cad189f48f5444a9abfe750dade2e000",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded and dataloaders created.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 13:17:56] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 13:17:56] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 13:17:56] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 13:17:57] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 13:17:57] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 13:17:57] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 13:17:57] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 13:17:57] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 13:17:57] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 13:17:57] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 13:17:57] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 13:17:57]   Platform system: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 13:17:57]   Python version: 3.11.12\n",
            "[codecarbon INFO @ 13:17:57]   CodeCarbon version: 3.0.1\n",
            "[codecarbon INFO @ 13:17:57]   Available RAM : 52.960 GB\n",
            "[codecarbon INFO @ 13:17:57]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 13:17:57]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 13:17:57]   GPU count: 1\n",
            "[codecarbon INFO @ 13:17:57]   GPU model: 1 x NVIDIA L4\n",
            "[codecarbon INFO @ 13:17:57] Emissions data (if any) will be saved to file /content/emissions.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "2025-05-16 13:17:57 Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:18:07] Energy consumed for RAM : 0.000056 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:18:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:07] Energy consumed for All CPU : 0.000118 kWh\n",
            "[codecarbon INFO @ 13:18:07] Energy consumed for all GPUs : 0.000193 kWh. Total GPU Power : 69.27360374781422 W\n",
            "[codecarbon INFO @ 13:18:07] 0.000366 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:18:17] Energy consumed for RAM : 0.000111 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:18:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:17] Energy consumed for All CPU : 0.000236 kWh\n",
            "[codecarbon INFO @ 13:18:17] Energy consumed for all GPUs : 0.000392 kWh. Total GPU Power : 71.93355308880794 W\n",
            "[codecarbon INFO @ 13:18:17] 0.000739 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:18:27] Energy consumed for RAM : 0.000167 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:18:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:27] Energy consumed for All CPU : 0.000354 kWh\n",
            "[codecarbon INFO @ 13:18:27] Energy consumed for all GPUs : 0.000592 kWh. Total GPU Power : 71.74488879056122 W\n",
            "[codecarbon INFO @ 13:18:27] 0.001112 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:18:37] Energy consumed for RAM : 0.000222 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:18:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:37] Energy consumed for All CPU : 0.000472 kWh\n",
            "[codecarbon INFO @ 13:18:37] Energy consumed for all GPUs : 0.000791 kWh. Total GPU Power : 71.77645807829259 W\n",
            "[codecarbon INFO @ 13:18:37] 0.001485 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:18:47] Energy consumed for RAM : 0.000278 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:18:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:47] Energy consumed for All CPU : 0.000590 kWh\n",
            "[codecarbon INFO @ 13:18:47] Energy consumed for all GPUs : 0.000990 kWh. Total GPU Power : 71.76575584225941 W\n",
            "[codecarbon INFO @ 13:18:47] 0.001858 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:18:57] Energy consumed for RAM : 0.000333 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:18:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:57] Energy consumed for All CPU : 0.000708 kWh\n",
            "[codecarbon INFO @ 13:18:57] Energy consumed for all GPUs : 0.001189 kWh. Total GPU Power : 71.75068286848756 W\n",
            "[codecarbon INFO @ 13:18:57] 0.002231 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:19:07] Energy consumed for RAM : 0.000389 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:19:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:07] Energy consumed for All CPU : 0.000826 kWh\n",
            "[codecarbon INFO @ 13:19:07] Energy consumed for all GPUs : 0.001389 kWh. Total GPU Power : 71.77165709273892 W\n",
            "[codecarbon INFO @ 13:19:07] 0.002604 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:19:17] Energy consumed for RAM : 0.000444 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:19:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:17] Energy consumed for All CPU : 0.000944 kWh\n",
            "[codecarbon INFO @ 13:19:17] Energy consumed for all GPUs : 0.001588 kWh. Total GPU Power : 71.8447769178297 W\n",
            "[codecarbon INFO @ 13:19:17] 0.002977 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:19:17] 0.017514 g.CO2eq/s mean an estimation of 552.329590949805 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:19:27] Energy consumed for RAM : 0.000500 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:19:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:27] Energy consumed for All CPU : 0.001062 kWh\n",
            "[codecarbon INFO @ 13:19:27] Energy consumed for all GPUs : 0.001788 kWh. Total GPU Power : 71.78477451393539 W\n",
            "[codecarbon INFO @ 13:19:27] 0.003349 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:19:37] Energy consumed for RAM : 0.000555 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:19:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:37] Energy consumed for All CPU : 0.001180 kWh\n",
            "[codecarbon INFO @ 13:19:37] Energy consumed for all GPUs : 0.001987 kWh. Total GPU Power : 71.86463697390779 W\n",
            "[codecarbon INFO @ 13:19:37] 0.003723 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:19:47] Energy consumed for RAM : 0.000611 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:19:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:47] Energy consumed for All CPU : 0.001298 kWh\n",
            "[codecarbon INFO @ 13:19:47] Energy consumed for all GPUs : 0.002186 kWh. Total GPU Power : 71.79041986095159 W\n",
            "[codecarbon INFO @ 13:19:47] 0.004095 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:19:57] Energy consumed for RAM : 0.000666 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:19:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:57] Energy consumed for All CPU : 0.001416 kWh\n",
            "[codecarbon INFO @ 13:19:57] Energy consumed for all GPUs : 0.002386 kWh. Total GPU Power : 71.93502850874458 W\n",
            "[codecarbon INFO @ 13:19:57] 0.004469 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:20:07] Energy consumed for RAM : 0.000722 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:20:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:07] Energy consumed for All CPU : 0.001534 kWh\n",
            "[codecarbon INFO @ 13:20:07] Energy consumed for all GPUs : 0.002586 kWh. Total GPU Power : 71.96092548160385 W\n",
            "[codecarbon INFO @ 13:20:07] 0.004842 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:20:17] Energy consumed for RAM : 0.000777 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:20:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:17] Energy consumed for All CPU : 0.001652 kWh\n",
            "[codecarbon INFO @ 13:20:17] Energy consumed for all GPUs : 0.002786 kWh. Total GPU Power : 71.93025971109975 W\n",
            "[codecarbon INFO @ 13:20:17] 0.005215 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:20:27] Energy consumed for RAM : 0.000833 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:20:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:27] Energy consumed for All CPU : 0.001770 kWh\n",
            "[codecarbon INFO @ 13:20:27] Energy consumed for all GPUs : 0.002986 kWh. Total GPU Power : 71.96106242279987 W\n",
            "[codecarbon INFO @ 13:20:27] 0.005589 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:20:37] Energy consumed for RAM : 0.000888 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:20:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:37] Energy consumed for All CPU : 0.001888 kWh\n",
            "[codecarbon INFO @ 13:20:37] Energy consumed for all GPUs : 0.003185 kWh. Total GPU Power : 71.97284472109564 W\n",
            "[codecarbon INFO @ 13:20:37] 0.005962 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:20:37] 0.017569 g.CO2eq/s mean an estimation of 554.0420300188047 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:20:47] Energy consumed for RAM : 0.000944 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:20:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:47] Energy consumed for All CPU : 0.002006 kWh\n",
            "[codecarbon INFO @ 13:20:47] Energy consumed for all GPUs : 0.003385 kWh. Total GPU Power : 71.93841286245409 W\n",
            "[codecarbon INFO @ 13:20:47] 0.006335 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:20:54 Epoch  1/5 done. Loss: Train 2.061, Test 2.082; and Acc: Train 0.132, Test 0.114\n",
            "2025-05-16 13:20:54 Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:20:57] Energy consumed for RAM : 0.001000 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:20:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:57] Energy consumed for All CPU : 0.002124 kWh\n",
            "[codecarbon INFO @ 13:20:57] Energy consumed for all GPUs : 0.003585 kWh. Total GPU Power : 71.94096555930652 W\n",
            "[codecarbon INFO @ 13:20:57] 0.006709 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:07] Energy consumed for RAM : 0.001055 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:21:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:07] Energy consumed for All CPU : 0.002242 kWh\n",
            "[codecarbon INFO @ 13:21:07] Energy consumed for all GPUs : 0.003785 kWh. Total GPU Power : 71.86250673357338 W\n",
            "[codecarbon INFO @ 13:21:07] 0.007082 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:17] Energy consumed for RAM : 0.001111 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:21:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:17] Energy consumed for All CPU : 0.002360 kWh\n",
            "[codecarbon INFO @ 13:21:17] Energy consumed for all GPUs : 0.003984 kWh. Total GPU Power : 71.75415658683195 W\n",
            "[codecarbon INFO @ 13:21:17] 0.007455 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:27] Energy consumed for RAM : 0.001166 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:21:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:27] Energy consumed for All CPU : 0.002478 kWh\n",
            "[codecarbon INFO @ 13:21:27] Energy consumed for all GPUs : 0.004183 kWh. Total GPU Power : 71.8967581588168 W\n",
            "[codecarbon INFO @ 13:21:27] 0.007828 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:37] Energy consumed for RAM : 0.001222 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:21:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:37] Energy consumed for All CPU : 0.002596 kWh\n",
            "[codecarbon INFO @ 13:21:37] Energy consumed for all GPUs : 0.004383 kWh. Total GPU Power : 71.74987940272197 W\n",
            "[codecarbon INFO @ 13:21:37] 0.008201 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:47] Energy consumed for RAM : 0.001277 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:21:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:47] Energy consumed for All CPU : 0.002714 kWh\n",
            "[codecarbon INFO @ 13:21:47] Energy consumed for all GPUs : 0.004582 kWh. Total GPU Power : 71.81638761384 W\n",
            "[codecarbon INFO @ 13:21:47] 0.008573 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:57] Energy consumed for RAM : 0.001333 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:21:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:57] Energy consumed for All CPU : 0.002832 kWh\n",
            "[codecarbon INFO @ 13:21:57] Energy consumed for all GPUs : 0.004782 kWh. Total GPU Power : 71.8490427550717 W\n",
            "[codecarbon INFO @ 13:21:57] 0.008946 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:21:57] 0.017561 g.CO2eq/s mean an estimation of 553.8097050861082 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:22:07] Energy consumed for RAM : 0.001388 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:22:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:07] Energy consumed for All CPU : 0.002950 kWh\n",
            "[codecarbon INFO @ 13:22:07] Energy consumed for all GPUs : 0.004981 kWh. Total GPU Power : 71.72509491927751 W\n",
            "[codecarbon INFO @ 13:22:07] 0.009319 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:22:17] Energy consumed for RAM : 0.001444 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:22:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:17] Energy consumed for All CPU : 0.003068 kWh\n",
            "[codecarbon INFO @ 13:22:17] Energy consumed for all GPUs : 0.005180 kWh. Total GPU Power : 71.78985501195316 W\n",
            "[codecarbon INFO @ 13:22:17] 0.009692 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:22:27] Energy consumed for RAM : 0.001499 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:22:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:27] Energy consumed for All CPU : 0.003186 kWh\n",
            "[codecarbon INFO @ 13:22:27] Energy consumed for all GPUs : 0.005381 kWh. Total GPU Power : 72.43539428967658 W\n",
            "[codecarbon INFO @ 13:22:27] 0.010067 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:22:37] Energy consumed for RAM : 0.001555 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:22:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:37] Energy consumed for All CPU : 0.003304 kWh\n",
            "[codecarbon INFO @ 13:22:37] Energy consumed for all GPUs : 0.005581 kWh. Total GPU Power : 71.88836679275069 W\n",
            "[codecarbon INFO @ 13:22:37] 0.010440 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:22:47] Energy consumed for RAM : 0.001610 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:22:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:47] Energy consumed for All CPU : 0.003422 kWh\n",
            "[codecarbon INFO @ 13:22:47] Energy consumed for all GPUs : 0.005780 kWh. Total GPU Power : 71.73717017234624 W\n",
            "[codecarbon INFO @ 13:22:47] 0.010813 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:22:57] Energy consumed for RAM : 0.001666 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:22:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:57] Energy consumed for All CPU : 0.003540 kWh\n",
            "[codecarbon INFO @ 13:22:57] Energy consumed for all GPUs : 0.005980 kWh. Total GPU Power : 71.98563472402977 W\n",
            "[codecarbon INFO @ 13:22:57] 0.011186 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:23:07] Energy consumed for RAM : 0.001721 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:23:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:07] Energy consumed for All CPU : 0.003658 kWh\n",
            "[codecarbon INFO @ 13:23:07] Energy consumed for all GPUs : 0.006180 kWh. Total GPU Power : 71.95246484926707 W\n",
            "[codecarbon INFO @ 13:23:07] 0.011559 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:23:17] Energy consumed for RAM : 0.001777 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:23:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:17] Energy consumed for All CPU : 0.003776 kWh\n",
            "[codecarbon INFO @ 13:23:17] Energy consumed for all GPUs : 0.006380 kWh. Total GPU Power : 71.98015293725959 W\n",
            "[codecarbon INFO @ 13:23:17] 0.011933 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:23:17] 0.017573 g.CO2eq/s mean an estimation of 554.1922095488687 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:23:27] Energy consumed for RAM : 0.001832 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:23:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:27] Energy consumed for All CPU : 0.003894 kWh\n",
            "[codecarbon INFO @ 13:23:27] Energy consumed for all GPUs : 0.006579 kWh. Total GPU Power : 71.96075066472937 W\n",
            "[codecarbon INFO @ 13:23:27] 0.012306 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:23:37] Energy consumed for RAM : 0.001888 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:23:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:37] Energy consumed for All CPU : 0.004012 kWh\n",
            "[codecarbon INFO @ 13:23:37] Energy consumed for all GPUs : 0.006779 kWh. Total GPU Power : 71.92280898640524 W\n",
            "[codecarbon INFO @ 13:23:37] 0.012679 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:23:47] Energy consumed for RAM : 0.001943 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:23:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:47] Energy consumed for All CPU : 0.004130 kWh\n",
            "[codecarbon INFO @ 13:23:47] Energy consumed for all GPUs : 0.006979 kWh. Total GPU Power : 71.97367743569022 W\n",
            "[codecarbon INFO @ 13:23:47] 0.013053 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:23:51 Epoch  2/5 done. Loss: Train 1.988, Test 2.022; and Acc: Train 0.268, Test 0.251\n",
            "2025-05-16 13:23:51 Epoch 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:23:57] Energy consumed for RAM : 0.001999 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:23:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:57] Energy consumed for All CPU : 0.004248 kWh\n",
            "[codecarbon INFO @ 13:23:57] Energy consumed for all GPUs : 0.007178 kWh. Total GPU Power : 71.81265447200411 W\n",
            "[codecarbon INFO @ 13:23:57] 0.013426 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:24:07] Energy consumed for RAM : 0.002054 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:24:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:07] Energy consumed for All CPU : 0.004366 kWh\n",
            "[codecarbon INFO @ 13:24:07] Energy consumed for all GPUs : 0.007378 kWh. Total GPU Power : 71.83676625797332 W\n",
            "[codecarbon INFO @ 13:24:07] 0.013799 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:24:17] Energy consumed for RAM : 0.002110 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:24:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:17] Energy consumed for All CPU : 0.004484 kWh\n",
            "[codecarbon INFO @ 13:24:17] Energy consumed for all GPUs : 0.007577 kWh. Total GPU Power : 71.7513289121871 W\n",
            "[codecarbon INFO @ 13:24:17] 0.014172 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:24:27] Energy consumed for RAM : 0.002166 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:24:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:27] Energy consumed for All CPU : 0.004602 kWh\n",
            "[codecarbon INFO @ 13:24:27] Energy consumed for all GPUs : 0.007777 kWh. Total GPU Power : 71.7715452359682 W\n",
            "[codecarbon INFO @ 13:24:27] 0.014544 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:24:37] Energy consumed for RAM : 0.002221 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:24:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:37] Energy consumed for All CPU : 0.004720 kWh\n",
            "[codecarbon INFO @ 13:24:37] Energy consumed for all GPUs : 0.007976 kWh. Total GPU Power : 71.97341048805923 W\n",
            "[codecarbon INFO @ 13:24:37] 0.014918 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:24:37] 0.017565 g.CO2eq/s mean an estimation of 553.9362699600123 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:24:47] Energy consumed for RAM : 0.002277 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:24:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:47] Energy consumed for All CPU : 0.004838 kWh\n",
            "[codecarbon INFO @ 13:24:47] Energy consumed for all GPUs : 0.008176 kWh. Total GPU Power : 71.77506673283364 W\n",
            "[codecarbon INFO @ 13:24:47] 0.015291 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:24:57] Energy consumed for RAM : 0.002332 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:24:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:57] Energy consumed for All CPU : 0.004956 kWh\n",
            "[codecarbon INFO @ 13:24:57] Energy consumed for all GPUs : 0.008375 kWh. Total GPU Power : 71.79528139375134 W\n",
            "[codecarbon INFO @ 13:24:57] 0.015663 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:07] Energy consumed for RAM : 0.002388 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:25:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:07] Energy consumed for All CPU : 0.005074 kWh\n",
            "[codecarbon INFO @ 13:25:07] Energy consumed for all GPUs : 0.008574 kWh. Total GPU Power : 71.7450355171008 W\n",
            "[codecarbon INFO @ 13:25:07] 0.016036 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:17] Energy consumed for RAM : 0.002443 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:25:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:17] Energy consumed for All CPU : 0.005192 kWh\n",
            "[codecarbon INFO @ 13:25:17] Energy consumed for all GPUs : 0.008774 kWh. Total GPU Power : 71.8206416742876 W\n",
            "[codecarbon INFO @ 13:25:17] 0.016409 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:27] Energy consumed for RAM : 0.002499 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:25:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:27] Energy consumed for All CPU : 0.005310 kWh\n",
            "[codecarbon INFO @ 13:25:27] Energy consumed for all GPUs : 0.008973 kWh. Total GPU Power : 71.7756250187043 W\n",
            "[codecarbon INFO @ 13:25:27] 0.016782 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:37] Energy consumed for RAM : 0.002554 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:25:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:37] Energy consumed for All CPU : 0.005428 kWh\n",
            "[codecarbon INFO @ 13:25:37] Energy consumed for all GPUs : 0.009173 kWh. Total GPU Power : 71.86006498705072 W\n",
            "[codecarbon INFO @ 13:25:37] 0.017155 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:47] Energy consumed for RAM : 0.002610 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:25:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:47] Energy consumed for All CPU : 0.005546 kWh\n",
            "[codecarbon INFO @ 13:25:47] Energy consumed for all GPUs : 0.009372 kWh. Total GPU Power : 71.81333840464578 W\n",
            "[codecarbon INFO @ 13:25:47] 0.017528 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:57] Energy consumed for RAM : 0.002665 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:25:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:57] Energy consumed for All CPU : 0.005664 kWh\n",
            "[codecarbon INFO @ 13:25:57] Energy consumed for all GPUs : 0.009572 kWh. Total GPU Power : 71.9339581517282 W\n",
            "[codecarbon INFO @ 13:25:57] 0.017901 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:25:57] 0.017558 g.CO2eq/s mean an estimation of 553.7122344251164 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:26:07] Energy consumed for RAM : 0.002721 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:26:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:07] Energy consumed for All CPU : 0.005782 kWh\n",
            "[codecarbon INFO @ 13:26:07] Energy consumed for all GPUs : 0.009772 kWh. Total GPU Power : 71.9550023679686 W\n",
            "[codecarbon INFO @ 13:26:07] 0.018275 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:26:17] Energy consumed for RAM : 0.002776 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:26:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:17] Energy consumed for All CPU : 0.005900 kWh\n",
            "[codecarbon INFO @ 13:26:17] Energy consumed for all GPUs : 0.009971 kWh. Total GPU Power : 71.94563595432463 W\n",
            "[codecarbon INFO @ 13:26:17] 0.018648 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:26:27] Energy consumed for RAM : 0.002832 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:26:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:27] Energy consumed for All CPU : 0.006018 kWh\n",
            "[codecarbon INFO @ 13:26:27] Energy consumed for all GPUs : 0.010171 kWh. Total GPU Power : 71.99313606003395 W\n",
            "[codecarbon INFO @ 13:26:27] 0.019021 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:26:37] Energy consumed for RAM : 0.002887 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:26:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:37] Energy consumed for All CPU : 0.006136 kWh\n",
            "[codecarbon INFO @ 13:26:37] Energy consumed for all GPUs : 0.010371 kWh. Total GPU Power : 71.93191410150861 W\n",
            "[codecarbon INFO @ 13:26:37] 0.019395 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:26:47] Energy consumed for RAM : 0.002943 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:26:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:47] Energy consumed for All CPU : 0.006254 kWh\n",
            "[codecarbon INFO @ 13:26:47] Energy consumed for all GPUs : 0.010571 kWh. Total GPU Power : 71.96239954505828 W\n",
            "[codecarbon INFO @ 13:26:47] 0.019768 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:26:47 Epoch  3/5 done. Loss: Train 1.966, Test 2.007; and Acc: Train 0.269, Test 0.252\n",
            "2025-05-16 13:26:47 Epoch 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:26:57] Energy consumed for RAM : 0.002998 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:26:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:57] Energy consumed for All CPU : 0.006372 kWh\n",
            "[codecarbon INFO @ 13:26:57] Energy consumed for all GPUs : 0.010771 kWh. Total GPU Power : 71.92320152628398 W\n",
            "[codecarbon INFO @ 13:26:57] 0.020141 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:27:07] Energy consumed for RAM : 0.003054 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:27:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:07] Energy consumed for All CPU : 0.006490 kWh\n",
            "[codecarbon INFO @ 13:27:07] Energy consumed for all GPUs : 0.010972 kWh. Total GPU Power : 72.48072689938952 W\n",
            "[codecarbon INFO @ 13:27:07] 0.020516 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:27:17] Energy consumed for RAM : 0.003109 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:27:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:17] Energy consumed for All CPU : 0.006608 kWh\n",
            "[codecarbon INFO @ 13:27:17] Energy consumed for all GPUs : 0.011171 kWh. Total GPU Power : 71.82475213778544 W\n",
            "[codecarbon INFO @ 13:27:17] 0.020889 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:27:17] 0.017581 g.CO2eq/s mean an estimation of 554.442249056337 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:27:27] Energy consumed for RAM : 0.003165 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:27:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:27] Energy consumed for All CPU : 0.006726 kWh\n",
            "[codecarbon INFO @ 13:27:27] Energy consumed for all GPUs : 0.011371 kWh. Total GPU Power : 71.81131243632434 W\n",
            "[codecarbon INFO @ 13:27:27] 0.021262 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:27:37] Energy consumed for RAM : 0.003221 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:27:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:37] Energy consumed for All CPU : 0.006844 kWh\n",
            "[codecarbon INFO @ 13:27:37] Energy consumed for all GPUs : 0.011570 kWh. Total GPU Power : 71.87590128143894 W\n",
            "[codecarbon INFO @ 13:27:37] 0.021635 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:27:47] Energy consumed for RAM : 0.003276 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:27:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:47] Energy consumed for All CPU : 0.006962 kWh\n",
            "[codecarbon INFO @ 13:27:47] Energy consumed for all GPUs : 0.011770 kWh. Total GPU Power : 71.8081083669294 W\n",
            "[codecarbon INFO @ 13:27:47] 0.022008 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:27:57] Energy consumed for RAM : 0.003332 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:27:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:57] Energy consumed for All CPU : 0.007080 kWh\n",
            "[codecarbon INFO @ 13:27:57] Energy consumed for all GPUs : 0.011969 kWh. Total GPU Power : 71.80831747272609 W\n",
            "[codecarbon INFO @ 13:27:57] 0.022381 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:28:07] Energy consumed for RAM : 0.003387 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:28:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:07] Energy consumed for All CPU : 0.007198 kWh\n",
            "[codecarbon INFO @ 13:28:07] Energy consumed for all GPUs : 0.012168 kWh. Total GPU Power : 71.80489850353268 W\n",
            "[codecarbon INFO @ 13:28:07] 0.022754 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:28:17] Energy consumed for RAM : 0.003443 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:28:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:17] Energy consumed for All CPU : 0.007316 kWh\n",
            "[codecarbon INFO @ 13:28:17] Energy consumed for all GPUs : 0.012368 kWh. Total GPU Power : 71.80612792684148 W\n",
            "[codecarbon INFO @ 13:28:17] 0.023127 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:28:27] Energy consumed for RAM : 0.003498 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:28:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:27] Energy consumed for All CPU : 0.007434 kWh\n",
            "[codecarbon INFO @ 13:28:27] Energy consumed for all GPUs : 0.012567 kWh. Total GPU Power : 71.78325433038069 W\n",
            "[codecarbon INFO @ 13:28:27] 0.023500 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:28:37] Energy consumed for RAM : 0.003554 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:28:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:37] Energy consumed for All CPU : 0.007552 kWh\n",
            "[codecarbon INFO @ 13:28:37] Energy consumed for all GPUs : 0.012766 kWh. Total GPU Power : 71.72766096088803 W\n",
            "[codecarbon INFO @ 13:28:37] 0.023872 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:28:37] 0.017556 g.CO2eq/s mean an estimation of 553.6311550414624 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:28:47] Energy consumed for RAM : 0.003609 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:28:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:47] Energy consumed for All CPU : 0.007670 kWh\n",
            "[codecarbon INFO @ 13:28:47] Energy consumed for all GPUs : 0.012966 kWh. Total GPU Power : 71.87910965617615 W\n",
            "[codecarbon INFO @ 13:28:47] 0.024246 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:28:57] Energy consumed for RAM : 0.003665 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:28:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:57] Energy consumed for All CPU : 0.007788 kWh\n",
            "[codecarbon INFO @ 13:28:57] Energy consumed for all GPUs : 0.013166 kWh. Total GPU Power : 71.95563120813735 W\n",
            "[codecarbon INFO @ 13:28:57] 0.024619 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:29:07] Energy consumed for RAM : 0.003720 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:29:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:07] Energy consumed for All CPU : 0.007906 kWh\n",
            "[codecarbon INFO @ 13:29:07] Energy consumed for all GPUs : 0.013366 kWh. Total GPU Power : 71.97367188556164 W\n",
            "[codecarbon INFO @ 13:29:07] 0.024992 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:29:17] Energy consumed for RAM : 0.003776 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:29:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:17] Energy consumed for All CPU : 0.008024 kWh\n",
            "[codecarbon INFO @ 13:29:17] Energy consumed for all GPUs : 0.013565 kWh. Total GPU Power : 71.99117085241342 W\n",
            "[codecarbon INFO @ 13:29:17] 0.025366 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:29:27] Energy consumed for RAM : 0.003831 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:29:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:27] Energy consumed for All CPU : 0.008142 kWh\n",
            "[codecarbon INFO @ 13:29:27] Energy consumed for all GPUs : 0.013765 kWh. Total GPU Power : 71.95872051545363 W\n",
            "[codecarbon INFO @ 13:29:27] 0.025739 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:29:37] Energy consumed for RAM : 0.003887 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:29:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:37] Energy consumed for All CPU : 0.008260 kWh\n",
            "[codecarbon INFO @ 13:29:37] Energy consumed for all GPUs : 0.013965 kWh. Total GPU Power : 71.96916772706956 W\n",
            "[codecarbon INFO @ 13:29:37] 0.026112 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:29:43 Epoch  4/5 done. Loss: Train 1.962, Test 2.008; and Acc: Train 0.269, Test 0.252\n",
            "2025-05-16 13:29:43 Epoch 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 13:29:47] Energy consumed for RAM : 0.003942 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:29:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:47] Energy consumed for All CPU : 0.008378 kWh\n",
            "[codecarbon INFO @ 13:29:47] Energy consumed for all GPUs : 0.014165 kWh. Total GPU Power : 71.87463944273982 W\n",
            "[codecarbon INFO @ 13:29:47] 0.026486 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:29:57] Energy consumed for RAM : 0.003998 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:29:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:57] Energy consumed for All CPU : 0.008496 kWh\n",
            "[codecarbon INFO @ 13:29:57] Energy consumed for all GPUs : 0.014364 kWh. Total GPU Power : 71.82402240888322 W\n",
            "[codecarbon INFO @ 13:29:57] 0.026859 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:29:57] 0.017572 g.CO2eq/s mean an estimation of 554.1418237870649 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:30:07] Energy consumed for RAM : 0.004053 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:30:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:07] Energy consumed for All CPU : 0.008614 kWh\n",
            "[codecarbon INFO @ 13:30:07] Energy consumed for all GPUs : 0.014563 kWh. Total GPU Power : 71.76484340440092 W\n",
            "[codecarbon INFO @ 13:30:07] 0.027231 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:30:17] Energy consumed for RAM : 0.004109 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:30:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:17] Energy consumed for All CPU : 0.008732 kWh\n",
            "[codecarbon INFO @ 13:30:17] Energy consumed for all GPUs : 0.014763 kWh. Total GPU Power : 71.84600015845865 W\n",
            "[codecarbon INFO @ 13:30:17] 0.027604 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:30:27] Energy consumed for RAM : 0.004164 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:30:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:27] Energy consumed for All CPU : 0.008850 kWh\n",
            "[codecarbon INFO @ 13:30:27] Energy consumed for all GPUs : 0.014962 kWh. Total GPU Power : 71.82538187005892 W\n",
            "[codecarbon INFO @ 13:30:27] 0.027977 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:30:37] Energy consumed for RAM : 0.004220 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:30:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:37] Energy consumed for All CPU : 0.008968 kWh\n",
            "[codecarbon INFO @ 13:30:37] Energy consumed for all GPUs : 0.015162 kWh. Total GPU Power : 71.80776329222826 W\n",
            "[codecarbon INFO @ 13:30:37] 0.028350 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:30:47] Energy consumed for RAM : 0.004275 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:30:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:47] Energy consumed for All CPU : 0.009086 kWh\n",
            "[codecarbon INFO @ 13:30:47] Energy consumed for all GPUs : 0.015361 kWh. Total GPU Power : 71.88778472114491 W\n",
            "[codecarbon INFO @ 13:30:47] 0.028723 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:30:57] Energy consumed for RAM : 0.004331 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:30:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:57] Energy consumed for All CPU : 0.009204 kWh\n",
            "[codecarbon INFO @ 13:30:57] Energy consumed for all GPUs : 0.015561 kWh. Total GPU Power : 71.70851235923597 W\n",
            "[codecarbon INFO @ 13:30:57] 0.029096 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:31:07] Energy consumed for RAM : 0.004387 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:31:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:07] Energy consumed for All CPU : 0.009322 kWh\n",
            "[codecarbon INFO @ 13:31:07] Energy consumed for all GPUs : 0.015760 kWh. Total GPU Power : 71.84959779701802 W\n",
            "[codecarbon INFO @ 13:31:07] 0.029469 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:31:17] Energy consumed for RAM : 0.004442 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:31:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:17] Energy consumed for All CPU : 0.009440 kWh\n",
            "[codecarbon INFO @ 13:31:17] Energy consumed for all GPUs : 0.015959 kWh. Total GPU Power : 71.80833299942901 W\n",
            "[codecarbon INFO @ 13:31:17] 0.029842 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:31:17] 0.017557 g.CO2eq/s mean an estimation of 553.6627590624373 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:31:27] Energy consumed for RAM : 0.004498 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:31:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:27] Energy consumed for All CPU : 0.009558 kWh\n",
            "[codecarbon INFO @ 13:31:27] Energy consumed for all GPUs : 0.016159 kWh. Total GPU Power : 71.83410678572893 W\n",
            "[codecarbon INFO @ 13:31:27] 0.030215 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:31:37] Energy consumed for RAM : 0.004553 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:31:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:37] Energy consumed for All CPU : 0.009676 kWh\n",
            "[codecarbon INFO @ 13:31:37] Energy consumed for all GPUs : 0.016358 kWh. Total GPU Power : 71.81836547395103 W\n",
            "[codecarbon INFO @ 13:31:37] 0.030588 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:31:47] Energy consumed for RAM : 0.004609 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:31:47] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:47] Energy consumed for All CPU : 0.009794 kWh\n",
            "[codecarbon INFO @ 13:31:47] Energy consumed for all GPUs : 0.016560 kWh. Total GPU Power : 72.64684738489427 W\n",
            "[codecarbon INFO @ 13:31:47] 0.030963 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:31:57] Energy consumed for RAM : 0.004664 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:31:57] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:57] Energy consumed for All CPU : 0.009912 kWh\n",
            "[codecarbon INFO @ 13:31:57] Energy consumed for all GPUs : 0.016760 kWh. Total GPU Power : 71.9728289660695 W\n",
            "[codecarbon INFO @ 13:31:57] 0.031337 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:32:07] Energy consumed for RAM : 0.004720 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:32:07] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:07] Energy consumed for All CPU : 0.010030 kWh\n",
            "[codecarbon INFO @ 13:32:07] Energy consumed for all GPUs : 0.016960 kWh. Total GPU Power : 71.98771424907467 W\n",
            "[codecarbon INFO @ 13:32:07] 0.031710 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:32:17] Energy consumed for RAM : 0.004775 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:32:17] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:17] Energy consumed for All CPU : 0.010148 kWh\n",
            "[codecarbon INFO @ 13:32:17] Energy consumed for all GPUs : 0.017160 kWh. Total GPU Power : 71.97313687566783 W\n",
            "[codecarbon INFO @ 13:32:17] 0.032083 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:32:27] Energy consumed for RAM : 0.004831 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:32:27] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:27] Energy consumed for All CPU : 0.010266 kWh\n",
            "[codecarbon INFO @ 13:32:27] Energy consumed for all GPUs : 0.017359 kWh. Total GPU Power : 71.94738064150927 W\n",
            "[codecarbon INFO @ 13:32:27] 0.032457 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:32:37] Energy consumed for RAM : 0.004886 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:32:37] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:37] Energy consumed for All CPU : 0.010384 kWh\n",
            "[codecarbon INFO @ 13:32:37] Energy consumed for all GPUs : 0.017559 kWh. Total GPU Power : 71.95295704034417 W\n",
            "[codecarbon INFO @ 13:32:37] 0.032830 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:32:37] 0.017584 g.CO2eq/s mean an estimation of 554.5290176684507 kg.CO2eq/year\n",
            "[codecarbon INFO @ 13:32:40] Energy consumed for RAM : 0.004902 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:32:40] Delta energy consumed for CPU with constant : 0.000034 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:40] Energy consumed for All CPU : 0.010418 kWh\n",
            "[codecarbon INFO @ 13:32:40] Energy consumed for all GPUs : 0.017617 kWh. Total GPU Power : 72.4746117526063 W\n",
            "[codecarbon INFO @ 13:32:40] 0.032938 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 13:32:40 Epoch  5/5 done. Loss: Train 1.960, Test 2.009; and Acc: Train 0.269, Test 0.252\n",
            "Training complete.\n",
            "Results for deberta-v3-base-freeze: {'model_name': 'DeBERTa v3 base with 8 frozen layers', 'batch_size': 32, 'epochs': 5, 'location': 'SGP', 'energy_consumed_kwh': 0.032937857461862084, 'carbon_emissions_kgco2': 0.015506583349467818, 'cpu_energy_kwh': 0.01041841919782986, 'gpu_energy_kwh': 0.01761721409376, 'ram_energy_kwh': 0.004902224170272229, 'hardware': [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 85W [generic]), GPU() (NVIDIA L4)], 'training_time': 884.3596179485321, 'accuracy': 0.25184577522559476, 'f1_score': 0.10133244167006238}\n",
            "Results for deberta-v3-base-freeze appended to /content/drive/MyDrive/Colab Notebooks/FrugalAI/results/train_results_20250516131155/running_results.csv\n",
            "All results saved to /content/drive/MyDrive/Colab Notebooks/FrugalAI/results/train_results_20250516131155/20250516131155_final_results.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "trained_models = {}\n",
        "results_list = []\n",
        "\n",
        "dataset = load_dataset(\"quotaclimat/frugalaichallenge-text-train\")\n",
        "\n",
        "# Create a directory to store the CSV files if it doesn't exist\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "output_dir = f\"/content/drive/MyDrive/Colab Notebooks/FrugalAI/results/train_results_{timestamp}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the CSV filename for all results\n",
        "all_results_filename = os.path.join(output_dir, \"running_results.csv\")\n",
        "\n",
        "# Create or open the CSV file in append mode\n",
        "csv_file_exists = os.path.exists(all_results_filename)\n",
        "\n",
        "for model_name, model_config in tqdm(models.items()):\n",
        "    print(f\"Training {model_name}\")\n",
        "\n",
        "    model, results = train_eval_model_with_tracking(\n",
        "        model_config=model_config,\n",
        "        dataset=dataset,\n",
        "        batch_size=32,\n",
        "        epochs=5,\n",
        "        lr=2e-5\n",
        "    )\n",
        "\n",
        "    trained_models[model_name] = model\n",
        "    results_list.append(results)\n",
        "    print(f\"Results for {model_name}: {results}\")\n",
        "\n",
        "    # Convert results to DataFrame and append to CSV\n",
        "    results_df = pd.DataFrame([results])  # Create DataFrame for current results\n",
        "    results_df.to_csv(all_results_filename, mode='a', header=not csv_file_exists, index=False)  # Append to CSV\n",
        "    csv_file_exists = True  # Set to True after the first write\n",
        "    print(f\"Results for {model_name} appended to {all_results_filename}\")\n",
        "\n",
        "# Save all results to a single CSV file\n",
        "all_results_df = pd.DataFrame(results_list)\n",
        "all_results_filename = os.path.join(output_dir, f\"{timestamp}_final_results.csv\")\n",
        "all_results_df.to_csv(all_results_filename, index=False)\n",
        "print(f\"All results saved to {all_results_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcGfYKb0nRYG"
      },
      "source": [
        "### Saving models and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZWCXi-lbeGk"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def pickle_models(models, results_list):\n",
        "  \"\"\"Pickles trained models and saves results.\n",
        "\n",
        "  Args:\n",
        "    models: A dictionary of trained models.\n",
        "    results_list: A list of dictionaries containing model results.\n",
        "  \"\"\"\n",
        "  for model_name, trained_model in models.items():\n",
        "    filename = os.path.join(output_dir, f\"{model_name}.pkl\")\n",
        "    try:\n",
        "      with open(filename, \"wb\") as file:\n",
        "        pickle.dump(trained_model, file)\n",
        "      print(f\"Model '{model_name}' pickled successfully to '{filename}'\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error pickling model '{model_name}': {e}\")\n",
        "\n",
        "  # Save results to a file\n",
        "  results_filename = os.path.join(output_dir, \"results.pkl\")\n",
        "  try:\n",
        "    with open(results_filename, \"wb\") as file:\n",
        "      pickle.dump(results_list, file)\n",
        "    print(f\"Results pickled successfully to '{results_filename}'\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error pickling results: {e}\")\n",
        "\n",
        "\n",
        "def load_pickled_models(directory):\n",
        "    \"\"\"Loads pickled models from a directory.\n",
        "\n",
        "    Args:\n",
        "        directory: The directory containing the pickled models.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary of loaded models.\n",
        "    \"\"\"\n",
        "    loaded_models = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".pkl\") and filename != \"results.pkl\":\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            try:\n",
        "                with open(filepath, \"rb\") as file:\n",
        "                    model_name = filename[:-4]  # Remove the .pkl extension\n",
        "                    loaded_models[model_name] = pickle.load(file)\n",
        "                    print(f\"Model '{model_name}' loaded successfully from '{filepath}'\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading model from '{filepath}': {e}\")\n",
        "    return loaded_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrWCHOApsPWe",
        "outputId": "51218630-f345-4f6f-a932-4894f8306328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 'roberta-base-freeze' pickled successfully to '/content/drive/MyDrive/Colab Notebooks/FrugalAI/saved_models/pickled_models_20250516135021/roberta-base-freeze.pkl'\n",
            "Model 'deberta-v3-base-freeze' pickled successfully to '/content/drive/MyDrive/Colab Notebooks/FrugalAI/saved_models/pickled_models_20250516135021/deberta-v3-base-freeze.pkl'\n",
            "Error pickling results: cannot pickle '_thread.RLock' object\n"
          ]
        }
      ],
      "source": [
        "# Create a directory to store the pickled models and results if it doesn't exist\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "output_dir = f\"/content/drive/MyDrive/Colab Notebooks/FrugalAI/saved_models/pickled_models_{timestamp}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "pickle_models(trained_models, results_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWgZBwqgik0K"
      },
      "source": [
        "## Measure inference consumption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzP1wADmsU8P",
        "outputId": "17ad3443-2d27-4e8c-ab75-771bb2d12380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading model from '/content/drive/MyDrive/Colab Notebooks/FrugalAI/saved_models/pickled_models_20250429025429/bert-base-uncased-freeze-10.pkl': Can't get attribute 'BertFreezeClassifier' on <module '__main__'>\n",
            "Error loading model from '/content/drive/MyDrive/Colab Notebooks/FrugalAI/saved_models/pickled_models_20250429025429/bert-base-uncased-freeze-8.pkl': Can't get attribute 'BertFreezeClassifier' on <module '__main__'>\n"
          ]
        }
      ],
      "source": [
        "models_directory = \"/content/drive/MyDrive/Colab Notebooks/FrugalAI/saved_models/pickled_models_20250429025429\" #  Replace with the actual directory\n",
        "\n",
        "loaded_models = load_pickled_models(models_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9GFiA-ExsM4"
      },
      "outputs": [],
      "source": [
        "loaded_models = trained_models\n",
        "\n",
        "# Assign the trained model to the model_config\n",
        "for name, model in loaded_models.items():\n",
        "    models[name]['model'] = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FF1KAUqq6Df"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def measure_inference_carbon(model_config, device, dataset, n_samples=1000):\n",
        "    model = model_config['model']\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_config['tokenizer'])\n",
        "    embedding_model = AutoModel.from_pretrained(model_config['tokenizer']).to(device)\n",
        "\n",
        "    tracker = EmissionsTracker(project_name=\"FrugalAI_inference_carbon\", measure_power_secs=10)\n",
        "    tracker.start()\n",
        "\n",
        "    inf_dataset = TextDataset(dataset['test']['quote'][:n_samples], dataset['test']['label'][:n_samples], tokenizer)\n",
        "    inf_dataloader = DataLoader(inf_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in inf_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            if isinstance(model, ConspiracyClassifier768):\n",
        "                embeddings = embedding_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
        "                outputs = model(embeddings)\n",
        "            else:\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "            predictions = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            # print(predictions)\n",
        "\n",
        "    emissions = tracker.stop()\n",
        "\n",
        "    results = {\n",
        "        \"model_name\": model_config['name'],\n",
        "        \"inf_energy_consumed_kwh\": tracker._total_energy.kWh,\n",
        "        \"inf_carbon_emissions_kgco2\": emissions,\n",
        "        'inf_cpu_energy_kwh': tracker._total_cpu_energy.kWh,\n",
        "        'inf_gpu_energy_kwh': tracker._total_gpu_energy.kWh,\n",
        "        'inf_ram_energy_kwh': tracker._total_ram_energy.kWh,\n",
        "        'inf_hardware': tracker._hardware,\n",
        "        'inf_location': tracker._geo.country_iso_code,\n",
        "    }\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yFIKJjxywML",
        "outputId": "be9d9ef0-16e0-45b8-85c9-ff1393dbf288"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[codecarbon WARNING @ 13:50:45] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 13:50:45] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 13:50:45] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 13:50:46] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 13:50:46] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 13:50:46] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 13:50:46] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 13:50:46] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 13:50:46] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 13:50:46] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 13:50:46] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 13:50:46]   Platform system: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 13:50:46]   Python version: 3.11.12\n",
            "[codecarbon INFO @ 13:50:46]   CodeCarbon version: 3.0.1\n",
            "[codecarbon INFO @ 13:50:46]   Available RAM : 52.960 GB\n",
            "[codecarbon INFO @ 13:50:46]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 13:50:46]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 13:50:46]   GPU count: 1\n",
            "[codecarbon INFO @ 13:50:46]   GPU model: 1 x NVIDIA L4\n",
            "[codecarbon INFO @ 13:50:46] Emissions data (if any) will be saved to file /content/emissions.csv\n",
            "[codecarbon INFO @ 13:50:52] Energy consumed for RAM : 0.000032 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:50:52] Delta energy consumed for CPU with constant : 0.000067 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:50:52] Energy consumed for All CPU : 0.000067 kWh\n",
            "[codecarbon INFO @ 13:50:52] Energy consumed for all GPUs : 0.000113 kWh. Total GPU Power : 71.0602167945244 W\n",
            "[codecarbon INFO @ 13:50:52] 0.000212 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'RoBERTa Base with 8 frozen layers', 'inf_energy_consumed_kwh': 0.0002118903419699449, 'inf_carbon_emissions_kgco2': 9.975437086363657e-05, 'inf_cpu_energy_kwh': 6.742011543194275e-05, 'inf_gpu_energy_kwh': 0.00011274897908800097, 'inf_ram_energy_kwh': 3.17212474500012e-05, 'inf_hardware': [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 85W [generic]), GPU() (NVIDIA L4)], 'inf_location': 'SGP'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "[codecarbon WARNING @ 13:50:55] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 13:50:55] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 13:50:55] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 13:50:56] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 13:50:56] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 13:50:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 13:50:56] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 13:50:56] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 13:50:56] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 13:50:56] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 13:50:56] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 13:50:56]   Platform system: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 13:50:56]   Python version: 3.11.12\n",
            "[codecarbon INFO @ 13:50:56]   CodeCarbon version: 3.0.1\n",
            "[codecarbon INFO @ 13:50:56]   Available RAM : 52.960 GB\n",
            "[codecarbon INFO @ 13:50:56]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 13:50:56]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 13:50:56]   GPU count: 1\n",
            "[codecarbon INFO @ 13:50:56]   GPU model: 1 x NVIDIA L4\n",
            "[codecarbon INFO @ 13:50:56] Emissions data (if any) will be saved to file /content/emissions.csv\n",
            "[codecarbon INFO @ 13:51:06] Energy consumed for RAM : 0.000056 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:51:06] Delta energy consumed for CPU with constant : 0.000118 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:51:06] Energy consumed for All CPU : 0.000118 kWh\n",
            "[codecarbon INFO @ 13:51:06] Energy consumed for all GPUs : 0.000198 kWh. Total GPU Power : 71.10980286735423 W\n",
            "[codecarbon INFO @ 13:51:06] 0.000371 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 13:51:06] Energy consumed for RAM : 0.000057 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 13:51:06] Delta energy consumed for CPU with constant : 0.000004 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 13:51:06] Energy consumed for All CPU : 0.000122 kWh\n",
            "[codecarbon INFO @ 13:51:06] Energy consumed for all GPUs : 0.000204 kWh. Total GPU Power : 61.95601314254132 W\n",
            "[codecarbon INFO @ 13:51:06] 0.000383 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'DeBERTa v3 base with 8 frozen layers', 'inf_energy_consumed_kwh': 0.0003832693277842747, 'inf_carbon_emissions_kgco2': 0.0001804366839422642, 'inf_cpu_energy_kwh': 0.00012218553378471692, 'inf_gpu_energy_kwh': 0.00020359682954400327, 'inf_ram_energy_kwh': 5.74869644555545e-05, 'inf_hardware': [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 85W [generic]), GPU() (NVIDIA L4)], 'inf_location': 'SGP'}\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"quotaclimat/frugalaichallenge-text-train\")\n",
        "\n",
        "inf_energy_results_list = []\n",
        "for model_config in models.values():\n",
        "    if not 'tfidf' in model_config['name'].lower():\n",
        "        # print(model_config)\n",
        "        inf_energy_results = measure_inference_carbon(model_config, device, dataset, n_samples=1000)\n",
        "        print(inf_energy_results)\n",
        "        inf_energy_results_list.append(inf_energy_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ju44n14oM9",
        "outputId": "0e529446-6a39-4e29-ce7f-3dc16c46846d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon WARNING @ 20:54:32] Multiple instances of codecarbon are allowed to run at the same time.\n",
            "[codecarbon INFO @ 20:54:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 20:54:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 20:54:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon WARNING @ 20:54:33] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
            " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
            "\n",
            "[codecarbon INFO @ 20:54:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon WARNING @ 20:54:33] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon INFO @ 20:54:33] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 20:54:33] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 20:54:33] The below tracking methods have been set up:\n",
            "                RAM Tracking Method: RAM power estimation model\n",
            "                CPU Tracking Method: global constant\n",
            "                GPU Tracking Method: pynvml\n",
            "            \n",
            "[codecarbon INFO @ 20:54:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 20:54:33]   Platform system: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 20:54:33]   Python version: 3.11.12\n",
            "[codecarbon INFO @ 20:54:33]   CodeCarbon version: 3.0.1\n",
            "[codecarbon INFO @ 20:54:33]   Available RAM : 52.960 GB\n",
            "[codecarbon INFO @ 20:54:33]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
            "[codecarbon INFO @ 20:54:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 20:54:33]   GPU count: 1\n",
            "[codecarbon INFO @ 20:54:33]   GPU model: 1 x NVIDIA L4\n",
            "[codecarbon INFO @ 20:54:33] Emissions data (if any) will be saved to file /content/emissions.csv\n",
            "[codecarbon INFO @ 20:54:34] Energy consumed for RAM : 0.000001 kWh. RAM Power : 20.0 W\n",
            "[codecarbon INFO @ 20:54:34] Delta energy consumed for CPU with constant : 0.000001 kWh, power : 42.5 W\n",
            "[codecarbon INFO @ 20:54:34] Energy consumed for All CPU : 0.000001 kWh\n",
            "[codecarbon INFO @ 20:54:34] Energy consumed for all GPUs : 0.000001 kWh. Total GPU Power : 33.40419342297219 W\n",
            "[codecarbon INFO @ 20:54:34] 0.000003 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model_name': 'TFIDF + XGBoost', 'inf_energy_consumed_kwh': 2.721015781491085e-06, 'inf_carbon_emissions_kgco2': 1.2810079726577175e-06, 'inf_cpu_energy_kwh': 1.2034305430650724e-06, 'inf_gpu_energy_kwh': 9.57778543975163e-07, 'inf_ram_energy_kwh': 5.598066944508497e-07, 'inf_hardware': [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 85W [generic]), GPU() (NVIDIA L4)], 'inf_location': 'SGP'}\n"
          ]
        }
      ],
      "source": [
        "# prompt: Evaluate the carbon intensity of the tfidf xgb model and produce the results in the same structureas measure_inference_carbon\n",
        "\n",
        "def measure_inference_carbon_tfidf(model_config, dataset, n_samples=200):\n",
        "    model = model_config['model']\n",
        "    tracker = EmissionsTracker(project_name=\"FrugalAI_inference_carbon\", measure_power_secs=10)\n",
        "    tracker.start()\n",
        "\n",
        "    predictions = model.predict(dataset['test']['quote'][:n_samples])\n",
        "    emissions = tracker.stop()\n",
        "\n",
        "    results = {\n",
        "        \"model_name\": model_config['name'],\n",
        "        \"inf_energy_consumed_kwh\": tracker._total_energy.kWh,\n",
        "        \"inf_carbon_emissions_kgco2\": emissions,\n",
        "        'inf_cpu_energy_kwh': tracker._total_cpu_energy.kWh,\n",
        "        'inf_gpu_energy_kwh': tracker._total_gpu_energy.kWh,\n",
        "        'inf_ram_energy_kwh': tracker._total_ram_energy.kWh,\n",
        "        'inf_hardware': tracker._hardware,\n",
        "        'inf_location': tracker._geo.country_iso_code,\n",
        "    }\n",
        "    return results\n",
        "\n",
        "inf_energy_results_tfidf = measure_inference_carbon_tfidf(models['tfidf-xgboost'], dataset, n_samples=1000)\n",
        "print(inf_energy_results_tfidf)\n",
        "inf_energy_results_list.append(inf_energy_results_tfidf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxTsGqwY4dPy"
      },
      "outputs": [],
      "source": [
        "inf_energy_df = pd.DataFrame(inf_energy_results_list)\n",
        "train_energy_df = pd.DataFrame(results_list)\n",
        "\n",
        "#.to_csv(\"/content/drive/MyDrive/Colab Notebooks/FrugalAI/0605_freeze_inference_results.csv\")\n",
        "# .to_csv(\"/content/drive/MyDrive/Colab Notebooks/FrugalAI/0506_freeze_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "JAWyPV4fiV0p",
        "outputId": "ad564385-63d1-4d3a-c034-635b8b07359d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"merged_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"DeBERTa v3 base with 8 frozen layers\",\n          \"RoBERTa Base with 8 frozen layers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 32,\n        \"max\": 32,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SGP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_consumed_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014491502778067215,\n        \"min\": 0.012443777693952045,\n        \"max\": 0.032937857461862084,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.032937857461862084\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carbon_emissions_kgco2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006822353152366818,\n        \"min\": 0.005858318994091826,\n        \"max\": 0.015506583349467818,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.015506583349467818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cpu_energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004583894123966064,\n        \"min\": 0.003935813959234715,\n        \"max\": 0.01041841919782986,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.01041841919782986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpu_energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007750734640341568,\n        \"min\": 0.006656020047034,\n        \"max\": 0.01761721409376,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.01761721409376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ram_energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0021568740137595846,\n        \"min\": 0.0018519436876833302,\n        \"max\": 0.004902224170272229,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.004902224170272229\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hardware\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"training_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 388.44065939709367,\n        \"min\": 335.02156925201416,\n        \"max\": 884.3596179485321,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          884.3596179485321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.25184577522559476,\n        \"max\": 0.25184577522559476,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.25184577522559476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.10133244167006238,\n        \"max\": 0.10133244167006238,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.10133244167006238\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_energy_consumed_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00012118324302218573,\n        \"min\": 0.0002118903419699449,\n        \"max\": 0.0003832693277842747,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0003832693277842747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_carbon_emissions_kgco2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.7051010699713664e-05,\n        \"min\": 9.975437086363657e-05,\n        \"max\": 0.0001804366839422642,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0001804366839422642\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_cpu_energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.872499869176482e-05,\n        \"min\": 6.742011543194275e-05,\n        \"max\": 0.00012218553378471692,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00012218553378471692\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_gpu_energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.423913111366061e-05,\n        \"min\": 0.00011274897908800097,\n        \"max\": 0.00020359682954400327,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00020359682954400327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_ram_energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8219113216760283e-05,\n        \"min\": 3.17212474500012e-05,\n        \"max\": 5.74869644555545e-05,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5.74869644555545e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_hardware\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inf_location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"SGP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "merged_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-266a4828-cde1-4412-830b-b828a6ba4320\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>location</th>\n",
              "      <th>energy_consumed_kwh</th>\n",
              "      <th>carbon_emissions_kgco2</th>\n",
              "      <th>cpu_energy_kwh</th>\n",
              "      <th>gpu_energy_kwh</th>\n",
              "      <th>ram_energy_kwh</th>\n",
              "      <th>hardware</th>\n",
              "      <th>training_time</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>inf_energy_consumed_kwh</th>\n",
              "      <th>inf_carbon_emissions_kgco2</th>\n",
              "      <th>inf_cpu_energy_kwh</th>\n",
              "      <th>inf_gpu_energy_kwh</th>\n",
              "      <th>inf_ram_energy_kwh</th>\n",
              "      <th>inf_hardware</th>\n",
              "      <th>inf_location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RoBERTa Base with 8 frozen layers</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>SGP</td>\n",
              "      <td>0.012444</td>\n",
              "      <td>0.005858</td>\n",
              "      <td>0.003936</td>\n",
              "      <td>0.006656</td>\n",
              "      <td>0.001852</td>\n",
              "      <td>[RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz &gt; 8...</td>\n",
              "      <td>335.021569</td>\n",
              "      <td>0.251846</td>\n",
              "      <td>0.101332</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>[RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz &gt; 8...</td>\n",
              "      <td>SGP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DeBERTa v3 base with 8 frozen layers</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>SGP</td>\n",
              "      <td>0.032938</td>\n",
              "      <td>0.015507</td>\n",
              "      <td>0.010418</td>\n",
              "      <td>0.017617</td>\n",
              "      <td>0.004902</td>\n",
              "      <td>[RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz &gt; 8...</td>\n",
              "      <td>884.359618</td>\n",
              "      <td>0.251846</td>\n",
              "      <td>0.101332</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>0.00018</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>[RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz &gt; 8...</td>\n",
              "      <td>SGP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-266a4828-cde1-4412-830b-b828a6ba4320')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-266a4828-cde1-4412-830b-b828a6ba4320 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-266a4828-cde1-4412-830b-b828a6ba4320');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2e65846-4dc4-48ae-8707-11aec0c745cd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2e65846-4dc4-48ae-8707-11aec0c745cd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2e65846-4dc4-48ae-8707-11aec0c745cd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_eab5da50-c90c-494a-84e5-9ac2168182c3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eab5da50-c90c-494a-84e5-9ac2168182c3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                             model_name  batch_size  epochs location  \\\n",
              "0     RoBERTa Base with 8 frozen layers          32       5      SGP   \n",
              "1  DeBERTa v3 base with 8 frozen layers          32       5      SGP   \n",
              "\n",
              "   energy_consumed_kwh  carbon_emissions_kgco2  cpu_energy_kwh  \\\n",
              "0             0.012444                0.005858        0.003936   \n",
              "1             0.032938                0.015507        0.010418   \n",
              "\n",
              "   gpu_energy_kwh  ram_energy_kwh  \\\n",
              "0        0.006656        0.001852   \n",
              "1        0.017617        0.004902   \n",
              "\n",
              "                                            hardware  training_time  accuracy  \\\n",
              "0  [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 8...     335.021569  0.251846   \n",
              "1  [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 8...     884.359618  0.251846   \n",
              "\n",
              "   f1_score  inf_energy_consumed_kwh  inf_carbon_emissions_kgco2  \\\n",
              "0  0.101332                 0.000212                     0.00010   \n",
              "1  0.101332                 0.000383                     0.00018   \n",
              "\n",
              "   inf_cpu_energy_kwh  inf_gpu_energy_kwh  inf_ram_energy_kwh  \\\n",
              "0            0.000067            0.000113            0.000032   \n",
              "1            0.000122            0.000204            0.000057   \n",
              "\n",
              "                                        inf_hardware inf_location  \n",
              "0  [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 8...          SGP  \n",
              "1  [RAM(), CPU(Intel(R) Xeon(R) CPU @ 2.20GHz > 8...          SGP  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df = pd.merge(train_energy_df, inf_energy_df, on='model_name')\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYpN7DEsXzbK",
        "outputId": "a44439f2-9dc9-4dcf-c300-5c67efdae4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame saved to /content/drive/MyDrive/Colab Notebooks/FrugalAI/results/0516_merged_results.csv\n"
          ]
        }
      ],
      "source": [
        "merged_df = pd.merge(train_energy_df, inf_energy_df, on='model_name')\n",
        "\n",
        "# Specify the desired file path\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/FrugalAI/results/0516_merged_results.csv\"\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "merged_df.to_csv(file_path, index=False)  # Set index=False to avoid saving row indices\n",
        "print(f\"DataFrame saved to {file_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "FrugalAI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "080168109e674466b8fda1a427a97c68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08cc1532e09c4c8ab3d91567ccbfef51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e88617d3374dd286d805e4f24aa260": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e238f16ea15494b827d374fa1895414": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13046dc8761541e3bebf328c72afd398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a20b62c740c845cfa764369b2c2b2dbf",
            "placeholder": "",
            "style": "IPY_MODEL_812c40705d894f4197eed3d54cb68aed",
            "value": "456k/456k[00:00&lt;00:00,1.03MB/s]"
          }
        },
        "1482db60b0b148219a1af377e314a836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15e5119de9a64878b3041b568c8bb5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86c6200dbf78495985faac7ebc3c13c8",
              "IPY_MODEL_84d6ab2621564ac29c2dd6413522b57e",
              "IPY_MODEL_fa804938437345ada6e20a165fb45c48"
            ],
            "layout": "IPY_MODEL_bf9214cc4c7646309a6d83d70ed05035"
          }
        },
        "16010d7c4b6b4d5f8cd20094f229d144": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18bf2c73af9a4db08663cb6b892d696a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aa87ed8695342cda6a3f67798409632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68c7df445a7b4e9aac4c729407beb599",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff783e0ce2ab489d96eecd75962e87bb",
            "value": 456318
          }
        },
        "20ba3181722045c3a2e02d1e5e78fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "273f384349204619a984c3faef9ca7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288539f842d54ed5ac9f3c73fe4f7e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d68f51d53f4ce58e2ffbaf73689c94",
            "placeholder": "",
            "style": "IPY_MODEL_18bf2c73af9a4db08663cb6b892d696a",
            "value": "52.0/52.0[00:00&lt;00:00,6.59kB/s]"
          }
        },
        "2e150f1b4500422eae399f07ab617043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fabe1d1cc54b06aa66e47d17c6d3aa",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34d85da4460740ba8192d3ca5cf003d5",
            "value": 2464616
          }
        },
        "34d85da4460740ba8192d3ca5cf003d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3570af93f3754f6eb8cd5a5495be3c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c827ebdad5049a8b1d1571c39f08deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4df74c468c72436280f9235de4af7750": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5030bba89344414c8415107d84db6c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_080168109e674466b8fda1a427a97c68",
            "placeholder": "",
            "style": "IPY_MODEL_c43938df871543d2bf97573ca66823b2",
            "value": "spm.model:100%"
          }
        },
        "53c6d028c83940dfa3428e6fdc3071b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f41fb38cac4991be53a686779003cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78212f68102642c4ac71a39a6939e682",
            "placeholder": "",
            "style": "IPY_MODEL_b136d121c449459fa93793c20bd2ba46",
            "value": "25.0/25.0[00:00&lt;00:00,3.15kB/s]"
          }
        },
        "5a944fd6229049508970b6809e378cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f974fd9b5afb4555986d967b6a617bd1",
              "IPY_MODEL_647661c1a199416684bf7142718131ee",
              "IPY_MODEL_58f41fb38cac4991be53a686779003cf"
            ],
            "layout": "IPY_MODEL_98730ba2164d424a9bf52d4ea537a2fb"
          }
        },
        "5ac94ead99494814abb25e8902fce452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e1e9b7008f449da86b25e6eb0985d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62584308dd864b318fb915bf1d24e67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c18183b7ce9490fb7621f82a775e6f4",
            "placeholder": "",
            "style": "IPY_MODEL_70dd9a5bf1f547169630d5356a23861c",
            "value": "tokenizer_config.json:100%"
          }
        },
        "63ae69ae808f4ad99ae9a801a010c179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ccd26bbd9642dcaa1be341a59faa9e",
            "placeholder": "",
            "style": "IPY_MODEL_3c827ebdad5049a8b1d1571c39f08deb",
            "value": "1.36M/1.36M[00:00&lt;00:00,1.98MB/s]"
          }
        },
        "647661c1a199416684bf7142718131ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e8b5e274c94fb6a2817304f806445c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a05e021b9e74845ad432e5213ddf1e2",
            "value": 25
          }
        },
        "68c7df445a7b4e9aac4c729407beb599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697a46fec4024ddfba776ea4ba884e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e238f16ea15494b827d374fa1895414",
            "placeholder": "",
            "style": "IPY_MODEL_5ac94ead99494814abb25e8902fce452",
            "value": "2/2[20:55&lt;00:00,676.23s/it]"
          }
        },
        "6c46f87504da4f3fa258c067f46f87c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c6d028c83940dfa3428e6fdc3071b6",
            "placeholder": "",
            "style": "IPY_MODEL_74eabd5c535d48d6a2613527faa5e274",
            "value": "tokenizer.json:100%"
          }
        },
        "70dd9a5bf1f547169630d5356a23861c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71d68f51d53f4ce58e2ffbaf73689c94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c3750099ed4d9b8790242bd2f427c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72fc86bfcaf74466851bcd1ed04c97ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74eabd5c535d48d6a2613527faa5e274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78212f68102642c4ac71a39a6939e682": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812c40705d894f4197eed3d54cb68aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d6ab2621564ac29c2dd6413522b57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72c3750099ed4d9b8790242bd2f427c7",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9c4e009ad96488798f584be79580d48",
            "value": 898823
          }
        },
        "86c6200dbf78495985faac7ebc3c13c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08cc1532e09c4c8ab3d91567ccbfef51",
            "placeholder": "",
            "style": "IPY_MODEL_3570af93f3754f6eb8cd5a5495be3c4f",
            "value": "vocab.json:100%"
          }
        },
        "880546ae3973404ea7929cb98fc7be35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e8b5e274c94fb6a2817304f806445c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98730ba2164d424a9bf52d4ea537a2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a05e021b9e74845ad432e5213ddf1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aa85b52e8dd49769f3817d5a8b4451e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed7187a02c640ab93102aa2833ca60d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf69da8220e34346ad8dc7243fbffe86",
            "value": 2
          }
        },
        "9c18183b7ce9490fb7621f82a775e6f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f57badf4825450e853ded9d536d1084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04fe8ed667846e78c6dc435d7b717f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a20b62c740c845cfa764369b2c2b2dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24345de7b4d4ca28110175604443a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72fc86bfcaf74466851bcd1ed04c97ee",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc43778e79344708a27d09ce5522b3eb",
            "value": 52
          }
        },
        "a8572f0a9e6b42eb9d92d9948a7632d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c46f87504da4f3fa258c067f46f87c8",
              "IPY_MODEL_b2f4a4ed440a4d6bb0c056d96aae5b84",
              "IPY_MODEL_63ae69ae808f4ad99ae9a801a010c179"
            ],
            "layout": "IPY_MODEL_08e88617d3374dd286d805e4f24aa260"
          }
        },
        "a86b0ae2a5c94e75ab1221d8ec10fb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62584308dd864b318fb915bf1d24e67a",
              "IPY_MODEL_a24345de7b4d4ca28110175604443a38",
              "IPY_MODEL_288539f842d54ed5ac9f3c73fe4f7e74"
            ],
            "layout": "IPY_MODEL_e483367bf2ba4af99828a69a3262783c"
          }
        },
        "ad30762e20e54ebd9416252c948a50e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc912834d1164d46b14877b6f6d5744f",
              "IPY_MODEL_1aa87ed8695342cda6a3f67798409632",
              "IPY_MODEL_13046dc8761541e3bebf328c72afd398"
            ],
            "layout": "IPY_MODEL_f70f8d63577a409c9975ec3083b6fd22"
          }
        },
        "b136d121c449459fa93793c20bd2ba46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2f4a4ed440a4d6bb0c056d96aae5b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880546ae3973404ea7929cb98fc7be35",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ced467c702cb4a36a26461445ccc9630",
            "value": 1355863
          }
        },
        "b832ef14dd1e4c51845c5b86dcaf6bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c4e009ad96488798f584be79580d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc912834d1164d46b14877b6f6d5744f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8895c24f4f2461bafcdc0373faaba77",
            "placeholder": "",
            "style": "IPY_MODEL_9f57badf4825450e853ded9d536d1084",
            "value": "merges.txt:100%"
          }
        },
        "bf69da8220e34346ad8dc7243fbffe86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf9214cc4c7646309a6d83d70ed05035": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ccd26bbd9642dcaa1be341a59faa9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43938df871543d2bf97573ca66823b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cad189f48f5444a9abfe750dade2e000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5030bba89344414c8415107d84db6c64",
              "IPY_MODEL_2e150f1b4500422eae399f07ab617043",
              "IPY_MODEL_d75ec8c5d74a44f7a8e4b2f69c00254c"
            ],
            "layout": "IPY_MODEL_16010d7c4b6b4d5f8cd20094f229d144"
          }
        },
        "cc43778e79344708a27d09ce5522b3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ced467c702cb4a36a26461445ccc9630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d676c93e4e654b00a70b81a912a48c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d75ec8c5d74a44f7a8e4b2f69c00254c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b832ef14dd1e4c51845c5b86dcaf6bb1",
            "placeholder": "",
            "style": "IPY_MODEL_a04fe8ed667846e78c6dc435d7b717f4",
            "value": "2.46M/2.46M[00:00&lt;00:00,112MB/s]"
          }
        },
        "d8895c24f4f2461bafcdc0373faaba77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fabe1d1cc54b06aa66e47d17c6d3aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd74ff432f444554a1646f427bd6a334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ba3181722045c3a2e02d1e5e78fbbe",
            "placeholder": "",
            "style": "IPY_MODEL_5e1e9b7008f449da86b25e6eb0985d1d",
            "value": "100%"
          }
        },
        "e483367bf2ba4af99828a69a3262783c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e727db4208914d249fda094b78d69979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37b38df4fc548f397169c23eef16e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd74ff432f444554a1646f427bd6a334",
              "IPY_MODEL_9aa85b52e8dd49769f3817d5a8b4451e",
              "IPY_MODEL_697a46fec4024ddfba776ea4ba884e96"
            ],
            "layout": "IPY_MODEL_e727db4208914d249fda094b78d69979"
          }
        },
        "f70f8d63577a409c9975ec3083b6fd22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f974fd9b5afb4555986d967b6a617bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273f384349204619a984c3faef9ca7f5",
            "placeholder": "",
            "style": "IPY_MODEL_d676c93e4e654b00a70b81a912a48c01",
            "value": "tokenizer_config.json:100%"
          }
        },
        "fa804938437345ada6e20a165fb45c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df74c468c72436280f9235de4af7750",
            "placeholder": "",
            "style": "IPY_MODEL_1482db60b0b148219a1af377e314a836",
            "value": "899k/899k[00:00&lt;00:00,1.38MB/s]"
          }
        },
        "fed7187a02c640ab93102aa2833ca60d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff783e0ce2ab489d96eecd75962e87bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
